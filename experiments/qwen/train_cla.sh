# Training models for CLA and fp8 KV recovery.

# CLA(2) adjacent - layer_idx : kv_cache_idx
CLA2_ADJ='{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 10, 12: 10, 13: 10, 14: 10, 15: 10, 16: 10, 17: 10, 18: 10, 19: 10, 20: 10, 21: 10, 22: 10, 23: 10, 24: 10, 25: 10, 26: 10, 27: 10, 28: 10, 29: 10, 30: 11, 31: 12, 32: 13, 33: 14, 34: 15, 35: 16, 36: 17, 37: 17, 38: 17, 39: 17, 40: 17, 41: 17, 42: 17, 43: 17, 44: 18, 45: 19, 46: 20, 47: 21, 48: 22, 49: 23, 50: 24, 51: 25, 52: 26, 53: 27, 54: 27, 55: 27, 56: 27, 57: 27, 58: 27, 59: 27, 60: 28, 61: 29, 62: 30, 63: 31}'

# CLA(2) no adjacent - layer_idx : kv_cache_idx
CLA2_NO_ADJ='{0: 0, 1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 4, 7: 5, 8: 6, 9: 6, 10: 7, 11: 7, 12: 8, 13: 8, 14: 8, 15: 9, 16: 9, 17: 10, 18: 10, 19: 10, 20: 11, 21: 11, 22: 12, 23: 12, 24: 12, 25: 12, 26: 13, 27: 13, 28: 14, 29: 14, 30: 15, 31: 15, 32: 16, 33: 16, 34: 17, 35: 17, 36: 18, 37: 18, 38: 19, 39: 19, 40: 19, 41: 19, 42: 20, 43: 20, 44: 21, 45: 21, 46: 22, 47: 22, 48: 22, 49: 23, 50: 23, 51: 24, 52: 24, 53: 25, 54: 25, 55: 26, 56: 26, 57: 27, 58: 27, 59: 28, 60: 28, 61: 29, 62: 30, 63: 31}'

# CLA(3) adjacent - layer_idx : kv_cache_idx
CLA3_ADJ='{0: 0, 1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 8, 11: 8, 12: 8, 13: 8, 14: 8, 15: 8, 16: 8, 17: 8, 18: 8, 19: 8, 20: 8, 21: 8, 22: 8, 23: 8, 24: 8, 25: 8, 26: 8, 27: 8, 28: 8, 29: 8, 30: 8, 31: 9, 32: 10, 33: 10, 34: 11, 35: 11, 36: 11, 37: 11, 38: 11, 39: 11, 40: 11, 41: 11, 42: 11, 43: 11, 44: 11, 45: 11, 46: 12, 47: 13, 48: 13, 49: 14, 50: 15, 51: 16, 52: 16, 53: 16, 54: 16, 55: 16, 56: 16, 57: 16, 58: 16, 59: 16, 60: 17, 61: 18, 62: 19, 63: 20}'

# CLA(3) no adjacent - layer_idx : kv_cache_idx
CLA3_NO_ADJ='{0: 0, 1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 4, 7: 5, 8: 6, 9: 6, 10: 7, 11: 7, 12: 7, 13: 7, 14: 7, 15: 7, 16: 7, 17: 7, 18: 7, 19: 7, 20: 7, 21: 7, 22: 7, 23: 7, 24: 7, 25: 7, 26: 7, 27: 7, 28: 8, 29: 8, 30: 9, 31: 9, 32: 10, 33: 10, 34: 11, 35: 11, 36: 12, 37: 12, 38: 12, 39: 12, 40: 12, 41: 12, 42: 12, 43: 12, 44: 13, 45: 13, 46: 14, 47: 14, 48: 14, 49: 15, 50: 15, 51: 16, 52: 16, 53: 17, 54: 17, 55: 17, 56: 17, 57: 17, 58: 17, 59: 17, 60: 17, 61: 18, 62: 19, 63: 20}'

# --cla_kv_cache_map "$CLA2_ADJ" \
# --project_name qwen_cla_fp8kv \

export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5
cd $HOME/git/fsdp_qlora && python train.py \
--world_size 6 \
--master_port 12356 \
--model_name Qwen/Qwen2.5-32B-Instruct \
--train_type full \
--sharding_strategy full_shard \
--precision bf16 \
--gradient_accumulation_steps 1 \
--batch_size 1 \
--context_length 1536 \
--use_gradient_checkpointing true \
--use_cpu_offload false \
--log_to wandb \
--dataset $HOME/data/qwen_large_mix_dataset_v0_dedup_1536 \
--verbose true \
--low_memory true