{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import safetensors\n",
    "import safetensors.torch\n",
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dora_weights = safetensors.torch.load_file(\"/workspace/models/Meta-Llama-3-1-405B-Instruct-4bit-DoRA/step_500/model_state_dict.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = json.load(open(\"/workspace/models/Meta-Llama-3-1-405B-Instruct-4bit-DoRA/step_500/config.json\"))[\"qlora_config\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\"meta-llama/Meta-Llama-3.1-405B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16384/(128/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_name_or_path\": \"meta-llama/Meta-Llama-3.1-405B-Instruct\",\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 128000,\n",
       "  \"eos_token_id\": [\n",
       "    128001,\n",
       "    128008,\n",
       "    128009\n",
       "  ],\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 16384,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 53248,\n",
       "  \"max_position_embeddings\": 131072,\n",
       "  \"mlp_bias\": false,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 128,\n",
       "  \"num_hidden_layers\": 126,\n",
       "  \"num_key_value_heads\": 8,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": {\n",
       "    \"factor\": 8.0,\n",
       "    \"high_freq_factor\": 4.0,\n",
       "    \"low_freq_factor\": 1.0,\n",
       "    \"original_max_position_embeddings\": 8192,\n",
       "    \"rope_type\": \"llama3\"\n",
       "  },\n",
       "  \"rope_theta\": 500000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.44.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 128256\n",
       "}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lora_target_modules': ['q_proj',\n",
       "  'k_proj',\n",
       "  'v_proj',\n",
       "  'o_proj',\n",
       "  'gate_proj',\n",
       "  'up_proj',\n",
       "  'down_proj'],\n",
       " 'compute_dtype': 'bfloat16',\n",
       " 'lora_rank': 64,\n",
       " 'layer_nbits': {'q_proj': 4,\n",
       "  'k_proj': 4,\n",
       "  'v_proj': 4,\n",
       "  'o_proj': 4,\n",
       "  'gate_proj': 4,\n",
       "  'up_proj': 4,\n",
       "  'down_proj': 4},\n",
       " 'layer_groupsizes': {'q_proj': 128,\n",
       "  'k_proj': 128,\n",
       "  'v_proj': 128,\n",
       "  'o_proj': 128,\n",
       "  'gate_proj': 128,\n",
       "  'up_proj': 128,\n",
       "  'down_proj': 128}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.0.mlp.down_proj.dora_layer.lora_A.weight torch.Size([64, 53248])\n",
      "model.layers.0.mlp.down_proj.dora_layer.lora_B.weight torch.Size([16384, 64])\n",
      "model.layers.0.mlp.down_proj.magnitude_layer.magnitude torch.Size([16384])\n",
      "model.layers.0.mlp.gate_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.0.mlp.gate_proj.dora_layer.lora_B.weight torch.Size([53248, 64])\n",
      "model.layers.0.mlp.gate_proj.magnitude_layer.magnitude torch.Size([53248])\n",
      "model.layers.0.mlp.up_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.0.mlp.up_proj.dora_layer.lora_B.weight torch.Size([53248, 64])\n",
      "model.layers.0.mlp.up_proj.magnitude_layer.magnitude torch.Size([53248])\n",
      "model.layers.0.self_attn.k_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.0.self_attn.k_proj.dora_layer.lora_B.weight torch.Size([2048, 64])\n",
      "model.layers.0.self_attn.k_proj.magnitude_layer.magnitude torch.Size([2048])\n",
      "model.layers.0.self_attn.o_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.0.self_attn.o_proj.dora_layer.lora_B.weight torch.Size([16384, 64])\n",
      "model.layers.0.self_attn.o_proj.magnitude_layer.magnitude torch.Size([16384])\n",
      "model.layers.0.self_attn.q_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.0.self_attn.q_proj.dora_layer.lora_B.weight torch.Size([16384, 64])\n",
      "model.layers.0.self_attn.q_proj.magnitude_layer.magnitude torch.Size([16384])\n",
      "model.layers.0.self_attn.v_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.0.self_attn.v_proj.dora_layer.lora_B.weight torch.Size([2048, 64])\n",
      "model.layers.0.self_attn.v_proj.magnitude_layer.magnitude torch.Size([2048])\n",
      "model.layers.1.mlp.down_proj.dora_layer.lora_A.weight torch.Size([64, 53248])\n",
      "model.layers.1.mlp.down_proj.dora_layer.lora_B.weight torch.Size([16384, 64])\n",
      "model.layers.1.mlp.down_proj.magnitude_layer.magnitude torch.Size([16384])\n",
      "model.layers.1.mlp.gate_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.1.mlp.gate_proj.dora_layer.lora_B.weight torch.Size([53248, 64])\n",
      "model.layers.1.mlp.gate_proj.magnitude_layer.magnitude torch.Size([53248])\n",
      "model.layers.1.mlp.up_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.1.mlp.up_proj.dora_layer.lora_B.weight torch.Size([53248, 64])\n",
      "model.layers.1.mlp.up_proj.magnitude_layer.magnitude torch.Size([53248])\n",
      "model.layers.1.self_attn.k_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.1.self_attn.k_proj.dora_layer.lora_B.weight torch.Size([2048, 64])\n",
      "model.layers.1.self_attn.k_proj.magnitude_layer.magnitude torch.Size([2048])\n",
      "model.layers.1.self_attn.o_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.1.self_attn.o_proj.dora_layer.lora_B.weight torch.Size([16384, 64])\n",
      "model.layers.1.self_attn.o_proj.magnitude_layer.magnitude torch.Size([16384])\n",
      "model.layers.1.self_attn.q_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.1.self_attn.q_proj.dora_layer.lora_B.weight torch.Size([16384, 64])\n",
      "model.layers.1.self_attn.q_proj.magnitude_layer.magnitude torch.Size([16384])\n",
      "model.layers.1.self_attn.v_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.1.self_attn.v_proj.dora_layer.lora_B.weight torch.Size([2048, 64])\n",
      "model.layers.1.self_attn.v_proj.magnitude_layer.magnitude torch.Size([2048])\n",
      "model.layers.2.mlp.down_proj.dora_layer.lora_A.weight torch.Size([64, 53248])\n",
      "model.layers.2.mlp.down_proj.dora_layer.lora_B.weight torch.Size([16384, 64])\n",
      "model.layers.2.mlp.down_proj.magnitude_layer.magnitude torch.Size([16384])\n",
      "model.layers.2.mlp.gate_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.2.mlp.gate_proj.dora_layer.lora_B.weight torch.Size([53248, 64])\n",
      "model.layers.2.mlp.gate_proj.magnitude_layer.magnitude torch.Size([53248])\n",
      "model.layers.2.mlp.up_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.2.mlp.up_proj.dora_layer.lora_B.weight torch.Size([53248, 64])\n",
      "model.layers.2.mlp.up_proj.magnitude_layer.magnitude torch.Size([53248])\n",
      "model.layers.2.self_attn.k_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.2.self_attn.k_proj.dora_layer.lora_B.weight torch.Size([2048, 64])\n",
      "model.layers.2.self_attn.k_proj.magnitude_layer.magnitude torch.Size([2048])\n",
      "model.layers.2.self_attn.o_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.2.self_attn.o_proj.dora_layer.lora_B.weight torch.Size([16384, 64])\n",
      "model.layers.2.self_attn.o_proj.magnitude_layer.magnitude torch.Size([16384])\n",
      "model.layers.2.self_attn.q_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.2.self_attn.q_proj.dora_layer.lora_B.weight torch.Size([16384, 64])\n",
      "model.layers.2.self_attn.q_proj.magnitude_layer.magnitude torch.Size([16384])\n",
      "model.layers.2.self_attn.v_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.2.self_attn.v_proj.dora_layer.lora_B.weight torch.Size([2048, 64])\n",
      "model.layers.2.self_attn.v_proj.magnitude_layer.magnitude torch.Size([2048])\n",
      "model.layers.3.mlp.down_proj.dora_layer.lora_A.weight torch.Size([64, 53248])\n",
      "model.layers.3.mlp.down_proj.dora_layer.lora_B.weight torch.Size([16384, 64])\n",
      "model.layers.3.mlp.down_proj.magnitude_layer.magnitude torch.Size([16384])\n",
      "model.layers.3.mlp.gate_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.3.mlp.gate_proj.dora_layer.lora_B.weight torch.Size([53248, 64])\n",
      "model.layers.3.mlp.gate_proj.magnitude_layer.magnitude torch.Size([53248])\n",
      "model.layers.3.mlp.up_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.3.mlp.up_proj.dora_layer.lora_B.weight torch.Size([53248, 64])\n",
      "model.layers.3.mlp.up_proj.magnitude_layer.magnitude torch.Size([53248])\n",
      "model.layers.3.self_attn.k_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.3.self_attn.k_proj.dora_layer.lora_B.weight torch.Size([2048, 64])\n",
      "model.layers.3.self_attn.k_proj.magnitude_layer.magnitude torch.Size([2048])\n",
      "model.layers.3.self_attn.o_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.3.self_attn.o_proj.dora_layer.lora_B.weight torch.Size([16384, 64])\n",
      "model.layers.3.self_attn.o_proj.magnitude_layer.magnitude torch.Size([16384])\n",
      "model.layers.3.self_attn.q_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.3.self_attn.q_proj.dora_layer.lora_B.weight torch.Size([16384, 64])\n",
      "model.layers.3.self_attn.q_proj.magnitude_layer.magnitude torch.Size([16384])\n",
      "model.layers.3.self_attn.v_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.3.self_attn.v_proj.dora_layer.lora_B.weight torch.Size([2048, 64])\n",
      "model.layers.3.self_attn.v_proj.magnitude_layer.magnitude torch.Size([2048])\n",
      "model.layers.4.mlp.down_proj.dora_layer.lora_A.weight torch.Size([64, 53248])\n",
      "model.layers.4.mlp.down_proj.dora_layer.lora_B.weight torch.Size([16384, 64])\n",
      "model.layers.4.mlp.down_proj.magnitude_layer.magnitude torch.Size([16384])\n",
      "model.layers.4.mlp.gate_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.4.mlp.gate_proj.dora_layer.lora_B.weight torch.Size([53248, 64])\n",
      "model.layers.4.mlp.gate_proj.magnitude_layer.magnitude torch.Size([53248])\n",
      "model.layers.4.mlp.up_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.4.mlp.up_proj.dora_layer.lora_B.weight torch.Size([53248, 64])\n",
      "model.layers.4.mlp.up_proj.magnitude_layer.magnitude torch.Size([53248])\n",
      "model.layers.4.self_attn.k_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.4.self_attn.k_proj.dora_layer.lora_B.weight torch.Size([2048, 64])\n",
      "model.layers.4.self_attn.k_proj.magnitude_layer.magnitude torch.Size([2048])\n",
      "model.layers.4.self_attn.o_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.4.self_attn.o_proj.dora_layer.lora_B.weight torch.Size([16384, 64])\n",
      "model.layers.4.self_attn.o_proj.magnitude_layer.magnitude torch.Size([16384])\n",
      "model.layers.4.self_attn.q_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.4.self_attn.q_proj.dora_layer.lora_B.weight torch.Size([16384, 64])\n",
      "model.layers.4.self_attn.q_proj.magnitude_layer.magnitude torch.Size([16384])\n",
      "model.layers.4.self_attn.v_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.4.self_attn.v_proj.dora_layer.lora_B.weight torch.Size([2048, 64])\n",
      "model.layers.4.self_attn.v_proj.magnitude_layer.magnitude torch.Size([2048])\n",
      "model.layers.5.mlp.down_proj.dora_layer.lora_A.weight torch.Size([64, 53248])\n",
      "model.layers.5.mlp.down_proj.dora_layer.lora_B.weight torch.Size([16384, 64])\n",
      "model.layers.5.mlp.down_proj.magnitude_layer.magnitude torch.Size([16384])\n",
      "model.layers.5.mlp.gate_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.5.mlp.gate_proj.dora_layer.lora_B.weight torch.Size([53248, 64])\n",
      "model.layers.5.mlp.gate_proj.magnitude_layer.magnitude torch.Size([53248])\n",
      "model.layers.5.mlp.up_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.5.mlp.up_proj.dora_layer.lora_B.weight torch.Size([53248, 64])\n",
      "model.layers.5.mlp.up_proj.magnitude_layer.magnitude torch.Size([53248])\n",
      "model.layers.5.self_attn.k_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.5.self_attn.k_proj.dora_layer.lora_B.weight torch.Size([2048, 64])\n",
      "model.layers.5.self_attn.k_proj.magnitude_layer.magnitude torch.Size([2048])\n",
      "model.layers.5.self_attn.o_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.5.self_attn.o_proj.dora_layer.lora_B.weight torch.Size([16384, 64])\n",
      "model.layers.5.self_attn.o_proj.magnitude_layer.magnitude torch.Size([16384])\n",
      "model.layers.5.self_attn.q_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.5.self_attn.q_proj.dora_layer.lora_B.weight torch.Size([16384, 64])\n",
      "model.layers.5.self_attn.q_proj.magnitude_layer.magnitude torch.Size([16384])\n",
      "model.layers.5.self_attn.v_proj.dora_layer.lora_A.weight torch.Size([64, 16384])\n",
      "model.layers.5.self_attn.v_proj.dora_layer.lora_B.weight torch.Size([2048, 64])\n",
      "model.layers.5.self_attn.v_proj.magnitude_layer.magnitude torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "for k,v in dora_weights.items():\n",
    "    if k.split(\".\")[2] in \"0 1 2 3 4 5\".split():\n",
    "\t    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w =dora_weights['model.layers.0.self_attn.k_proj.dora_layer.lora_B.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048, 64])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8328e-06,  7.8082e-06, -8.2254e-06,  ...,  4.2319e-06,\n",
       "          2.1309e-06, -1.0878e-06],\n",
       "        [ 8.3074e-07, -2.0489e-07, -1.2014e-07,  ...,  1.1772e-06,\n",
       "          1.5870e-06, -1.1781e-07],\n",
       "        [-7.8231e-07,  3.1199e-08,  1.1921e-06,  ...,  2.0862e-07,\n",
       "         -2.9989e-07,  2.7195e-07],\n",
       "        ...,\n",
       "        [-6.2957e-07,  5.3048e-06, -7.8678e-06,  ...,  4.6194e-06,\n",
       "          2.1756e-06,  8.0559e-08],\n",
       "        [ 8.4639e-06, -3.3855e-05,  7.6294e-05,  ..., -3.4571e-05,\n",
       "         -1.0133e-05,  7.0408e-07],\n",
       "        [ 1.8179e-06,  3.5912e-06, -1.1146e-05,  ...,  5.6922e-06,\n",
       "          2.7716e-06,  1.0505e-06]], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[:1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.0054e-05,  1.4973e-04, -2.2602e-04,  ...,  1.6117e-04,\n",
       "          9.1553e-05, -2.1219e-05],\n",
       "        [ 3.5286e-05, -5.1737e-05,  7.2956e-05,  ..., -4.7922e-05,\n",
       "         -1.9670e-05, -8.8215e-06],\n",
       "        [-6.1989e-05,  8.4877e-05, -8.6308e-05,  ...,  5.7459e-05,\n",
       "          4.2439e-05, -2.7776e-05],\n",
       "        ...,\n",
       "        [-3.0398e-06, -5.6326e-06,  6.4850e-05,  ..., -3.1233e-05,\n",
       "         -8.1584e-07, -1.0610e-05],\n",
       "        [-2.9564e-05,  1.8239e-05, -7.8201e-05,  ...,  2.4676e-05,\n",
       "         -1.2398e-05,  2.8312e-06],\n",
       "        [-2.6464e-05,  2.8372e-05, -7.4387e-05,  ...,  2.7895e-05,\n",
       "         -4.9174e-06, -2.2054e-06]], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[1024:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
