{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88954bae-0756-4fc5-9b77-a9e6e2ce9fb3",
   "metadata": {},
   "source": [
    "Prepare IFT datasets with `{\"input_text\":, ... \"output_text\":...}` format. Prepare in chat format to finetune chat models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be0d988a-baed-44c9-a83b-e4b4858d87ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/py_venvs/qdora/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import concatenate_datasets, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bb21107-ce34-463b-9755-bdcaf101dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chat_text(tokenizer, user_prompt, system=\"You are a helpful AI assistant.\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    return messages, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc853a14-fa20-49de-b173-ef9ad30c0f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c25ab-14a6-4e22-bc64-a7c352972da3",
   "metadata": {},
   "source": [
    "### oasst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0426a8db-f0aa-484c-bd84-1994f9666d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_example(example):\n",
    "    t = example[\"text\"]\n",
    "    \n",
    "    human_prefix, asst_prefix = \"### Human: \", \"### Assistant: \"\n",
    "    human_matches = list(re.finditer(human_prefix, t))\n",
    "    asst_matches = list(re.finditer(asst_prefix, t))\n",
    "    human_start_idx, _ = human_matches[0].span(0)\n",
    "    asst_start_idx, _ = asst_matches[0].span(0)\n",
    "    if len(human_matches) > 1:\n",
    "        asst_end_idx = human_matches[1].span(0)[0]\n",
    "    else:\n",
    "        asst_end_idx = len(t)\n",
    "    \n",
    "    human_prompt = t[human_start_idx+len(human_prefix):asst_start_idx]\n",
    "    asst_prompt = t[asst_start_idx+len(asst_prefix):asst_end_idx]\n",
    "    \n",
    "    _,input_text = create_chat_text(tokenizer, human_prompt)\n",
    "    output_text = asst_prompt\n",
    "    return {\"input_text\":input_text, \"output_text\":output_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21607f69-ac2c-48be-ac7c-25aef1f1d4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 395/395 [00:00<00:00, 1.30MB/s]\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Downloading data: 100%|██████████| 20.9M/20.9M [00:00<00:00, 22.3MB/s]\n",
      "Downloading data: 100%|██████████| 1.11M/1.11M [00:00<00:00, 17.6MB/s]\n",
      "Generating train split: 100%|██████████| 9846/9846 [00:00<00:00, 250452.53 examples/s]\n",
      "Generating test split: 100%|██████████| 518/518 [00:00<00:00, 79965.02 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds1 = load_dataset(\"timdettmers/openassistant-guanaco\")['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c10d8fb-65c8-4f70-ad0c-77c06d8cce87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9846/9846 [00:00<00:00, 9978.76 examples/s] \n"
     ]
    }
   ],
   "source": [
    "train_ds1_processed = train_ds1.map(process_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "910cfceb-a66c-4efe-93b7-7585ceb88690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9846"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds1_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "622a13ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful AI assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "\"Monopsony\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as the employer has little incentive to increase wages or provide better working conditions.\n",
      "\n",
      "Recent research has identified potential monopsonies in industries such as retail and fast food, where a few large companies control a significant portion of the market (Bivens & Mishel, 2013). In these industries, workers often face low wages, limited benefits, and reduced bargaining power, leading to a situation where they are dependent on the employer for their livelihood. This dependence can result in further suppression of wages and a decline in working conditions.\n",
      "\n",
      "Overall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue.\n",
      "\n",
      "References:\n",
      "Bivens, J., & Mishel, L. (2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.\n"
     ]
    }
   ],
   "source": [
    "print(train_ds1_processed[0]['input_text'])\n",
    "print(train_ds1_processed[0]['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8befe39e-e090-4b6b-b980-fe1566dbdbc1",
   "metadata": {},
   "source": [
    "### orca-math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8c2520a-e078-497c-b9db-a82047325fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_example(example):\n",
    "    _,input_text = create_chat_text(tokenizer, example['question'])\n",
    "    return {\"input_text\":input_text, \"output_text\":example['answer']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11937249-cc2a-4e04-a33f-534629317ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 6.91k/6.91k [00:00<00:00, 6.57MB/s]\n",
      "Downloading data: 100%|██████████| 84.2M/84.2M [00:00<00:00, 174MB/s] \n",
      "Generating train split: 100%|██████████| 200035/200035 [00:00<00:00, 243547.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds2 = load_dataset(\"microsoft/orca-math-word-problems-200k\")\n",
    "train_ds2 = train_ds2['train'].shuffle(42).select(range(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccbdd733-d301-4cfe-8d8e-0ce7ee2f6e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:01<00:00, 7254.98 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds2_processed = train_ds2.map(process_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b54a5325-80c2-4884-8b4b-b4533c3baaf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Quentin, Skylar, and Colten have a total of 383 chickens. Quentin has 25 more than double the chickens that Skylar has. Skylar has 4 less than a certain multiple of the number of chickens that Colten has. Colten has 37 chickens. What is the multiple of the number of chickens Colten has that Skylar has 4 less than?',\n",
       " 'answer': \"Let's denote the number of chickens that Skylar has as S and the number of chickens that Quentin has as Q. We know that Colten has 37 chickens.\\n\\nAccording to the information given:\\n\\n1) Quentin has 25 more than double the chickens that Skylar has:\\nQ = 2S + 25\\n\\n2) The total number of chickens is 383:\\nQ + S + 37 = 383\\n\\nNow, let's substitute the expression for Q from the first equation into the second equation:\\n\\n(2S + 25) + S + 37 = 383\\n3S + 62 = 383\\n3S = 383 - 62\\n3S = 321\\nS = 321 / 3\\nS = 107\\n\\nNow we know Skylar has 107 chickens.\\n\\nThe problem states that Skylar has 4 less than a certain multiple of the number of chickens that Colten has. Let's denote the multiple as M. So:\\n\\nS = M * 37 - 4\\n\\nWe already know S is 107, so:\\n\\n107 = M * 37 - 4\\n111 = M * 37\\nM = 111 / 37\\nM = 3\\n\\nTherefore, the multiple of the number of chickens Colten has that Skylar has 4 less than is 3.\",\n",
       " 'input_text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nQuentin, Skylar, and Colten have a total of 383 chickens. Quentin has 25 more than double the chickens that Skylar has. Skylar has 4 less than a certain multiple of the number of chickens that Colten has. Colten has 37 chickens. What is the multiple of the number of chickens Colten has that Skylar has 4 less than?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n',\n",
       " 'output_text': \"Let's denote the number of chickens that Skylar has as S and the number of chickens that Quentin has as Q. We know that Colten has 37 chickens.\\n\\nAccording to the information given:\\n\\n1) Quentin has 25 more than double the chickens that Skylar has:\\nQ = 2S + 25\\n\\n2) The total number of chickens is 383:\\nQ + S + 37 = 383\\n\\nNow, let's substitute the expression for Q from the first equation into the second equation:\\n\\n(2S + 25) + S + 37 = 383\\n3S + 62 = 383\\n3S = 383 - 62\\n3S = 321\\nS = 321 / 3\\nS = 107\\n\\nNow we know Skylar has 107 chickens.\\n\\nThe problem states that Skylar has 4 less than a certain multiple of the number of chickens that Colten has. Let's denote the multiple as M. So:\\n\\nS = M * 37 - 4\\n\\nWe already know S is 107, so:\\n\\n107 = M * 37 - 4\\n111 = M * 37\\nM = 111 / 37\\nM = 3\\n\\nTherefore, the multiple of the number of chickens Colten has that Skylar has 4 less than is 3.\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds2_processed[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4be20282-b79c-42bd-b152-d9614954a911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds2_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1741d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful AI assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Sally had 13 peaches at her roadside fruit dish.  She went to the orchard and picked peaches to stock up. She picked 55 peaches. There are _____ peaches now.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "Sally originally had 13 peaches. She picked 55 more peaches. To find out the total number of peaches she has now, we add the two amounts together:\n",
      "\n",
      "13 (original peaches) + 55 (picked peaches) = 68 peaches\n",
      "\n",
      "So, there are 68 peaches now.\n"
     ]
    }
   ],
   "source": [
    "print(train_ds2_processed[0]['input_text'])\n",
    "print(train_ds2_processed[0]['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc438a-d654-48de-ab93-ab4e22b4647c",
   "metadata": {},
   "source": [
    "### meta-math-qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50d080e0-ce10-494d-aed7-790067a854c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_example(example):\n",
    "    _,input_text = create_chat_text(tokenizer, example['query'])\n",
    "    return {\"input_text\":input_text, \"output_text\":example['response']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08a3022d-46ca-4a8f-b33b-45a52ba109e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 4.45k/4.45k [00:00<00:00, 4.68MB/s]\n",
      "Downloading data: 100%|██████████| 396M/396M [00:09<00:00, 43.4MB/s] \n",
      "Generating train split: 100%|██████████| 395000/395000 [00:07<00:00, 54893.41 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds3 = load_dataset(\"meta-math/MetaMathQA\")\n",
    "train_ds3 = train_ds3['train'].shuffle(42).select(range(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5c70ea5-5b0b-471b-b558-2604f1448514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:01<00:00, 6723.92 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds3_processed = train_ds3.map(process_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03ab6be5-8645-456d-b71e-93b9f60b7c82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'MATH_SV',\n",
       " 'query': 'Compute the sum of the squares of the roots of the equation \\\\[x^{2018} +44x^{2015} + 3x^3 + 404 = X The answer is 0. What is the value of unknown variable X?',\n",
       " 'original_question': 'Compute the sum of the squares of the roots of the equation \\\\[x^{2018} +44x^{2015} + 3x^3 + 404 = 0.\\\\]',\n",
       " 'response': 'To solve this problem, we need to determine the value of x that will make the sum of the squares of the roots of the equation equal to 0.\\nThe equation is given as:\\n\\\\[x^{2018} + 44x^{2015} + 3x^3 + 404 = X\\\\]\\nTo find the sum of the squares of the roots, we need to find the roots of the equation and then square them.\\nSince the answer is 0, it means that the sum of the squares of the roots must be equal to 0.\\nTo make the sum of squares 0, we need to find the values of x that will make each square equal to 0.\\nIf a square is equal to 0, it means that the value inside the square must be 0.\\nIn this case, we need to set each term inside the square to 0 and solve for x.\\nSetting each term to 0, we have:\\n\\\\[x^{2018} = 0\\\\]\\n\\\\[44x^{2015} = 0\\\\]\\n\\\\[3x^3 = 0\\\\]\\n\\\\[404 = 0\\\\]\\nThe last equation, 404 = 0, does not have a solution because it is a contradiction.\\nThe third equation, 3x^3 = 0, has a solution of x = 0.\\nThe second equation, 44x^{2015} = 0, also has a solution of x = 0.\\nThe first equation, x^{2018} = 0, has a solution of x = 0.\\nTherefore, the value of unknown variable x is 0.\\nThe answer is: 0',\n",
       " 'input_text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nCompute the sum of the squares of the roots of the equation \\\\[x^{2018} +44x^{2015} + 3x^3 + 404 = X The answer is 0. What is the value of unknown variable X?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n',\n",
       " 'output_text': 'To solve this problem, we need to determine the value of x that will make the sum of the squares of the roots of the equation equal to 0.\\nThe equation is given as:\\n\\\\[x^{2018} + 44x^{2015} + 3x^3 + 404 = X\\\\]\\nTo find the sum of the squares of the roots, we need to find the roots of the equation and then square them.\\nSince the answer is 0, it means that the sum of the squares of the roots must be equal to 0.\\nTo make the sum of squares 0, we need to find the values of x that will make each square equal to 0.\\nIf a square is equal to 0, it means that the value inside the square must be 0.\\nIn this case, we need to set each term inside the square to 0 and solve for x.\\nSetting each term to 0, we have:\\n\\\\[x^{2018} = 0\\\\]\\n\\\\[44x^{2015} = 0\\\\]\\n\\\\[3x^3 = 0\\\\]\\n\\\\[404 = 0\\\\]\\nThe last equation, 404 = 0, does not have a solution because it is a contradiction.\\nThe third equation, 3x^3 = 0, has a solution of x = 0.\\nThe second equation, 44x^{2015} = 0, also has a solution of x = 0.\\nThe first equation, x^{2018} = 0, has a solution of x = 0.\\nTherefore, the value of unknown variable x is 0.\\nThe answer is: 0'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds3_processed[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eefadd93-8ca7-41d6-a4f9-4d3f237a6deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds3_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7ce57b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful AI assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "If Anna wants to create a smiley face shape using red and yellow tulips, she requires 8 red tulips for each eye and 18 red tulips for the smile. Additionally, she needs 9 times the number of tulips in the smile to create the yellow background of the face. What is the total number of tulips that Anna needs?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "Anna needs 8 red tulips for each eye, so for both eyes she needs 8 * 2 = 16 red tulips.\n",
      "She also needs 18 red tulips for the smile.\n",
      "The total number of red tulips she needs is 16 + 18 = 34 red tulips.\n",
      "For the yellow background, she needs 9 times the number of tulips in the smile, so she needs 9 * 18 = 162 yellow tulips.\n",
      "The total number of tulips she needs is 34 + 162 = 196 tulips.\n",
      "#### 196\n",
      "The answer is: 196\n"
     ]
    }
   ],
   "source": [
    "print(train_ds3_processed[0]['input_text'])\n",
    "print(train_ds3_processed[0]['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd1706e-ed2b-4ba9-9a4c-92f3268f9a47",
   "metadata": {},
   "source": [
    "### ultrafeedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "349d5080-bbac-4906-ab7d-484bcb7bdbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_example(example):\n",
    "    chosen = example['chosen']\n",
    "    _,input_text = create_chat_text(tokenizer, chosen[0]['content'])\n",
    "    return {\"input_text\":input_text, \"output_text\":chosen[1]['content']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54487bae-7126-44c7-b9ed-eb7c40191adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 6.77k/6.77k [00:00<00:00, 7.51MB/s]\n",
      "Downloading data: 100%|██████████| 226M/226M [00:01<00:00, 159MB/s]  \n",
      "Downloading data: 100%|██████████| 226M/226M [00:00<00:00, 226MB/s]  \n",
      "Downloading data: 100%|██████████| 7.29M/7.29M [00:00<00:00, 66.0MB/s]\n",
      "Downloading data: 100%|██████████| 3.72M/3.72M [00:00<00:00, 35.2MB/s]\n",
      "Downloading data: 100%|██████████| 184M/184M [00:00<00:00, 221MB/s]  \n",
      "Downloading data: 100%|██████████| 3.02M/3.02M [00:00<00:00, 26.8MB/s]\n",
      "Generating train_prefs split: 100%|██████████| 61135/61135 [00:01<00:00, 51651.31 examples/s]\n",
      "Generating train_sft split: 100%|██████████| 61135/61135 [00:01<00:00, 55942.33 examples/s]\n",
      "Generating test_prefs split: 100%|██████████| 2000/2000 [00:00<00:00, 44999.40 examples/s]\n",
      "Generating test_sft split: 100%|██████████| 1000/1000 [00:00<00:00, 43104.71 examples/s]\n",
      "Generating train_gen split: 100%|██████████| 61135/61135 [00:00<00:00, 61933.34 examples/s]\n",
      "Generating test_gen split: 100%|██████████| 1000/1000 [00:00<00:00, 46453.18 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds4 = load_dataset('HuggingFaceH4/ultrafeedback_binarized')\n",
    "train_ds4 = train_ds4['train_sft'].shuffle(42).select(range(10000))\n",
    "train_ds4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8eb22bbc-2513-4ad6-9476-2eb69618eeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:02<00:00, 4761.43 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds4_processed = train_ds4.map(process_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea200f8f-a07b-4a79-8047-b17b006ea674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds4_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a793ebf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful AI assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Do you know something about crystallography and structure factor?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "Crystallography is the science of the arrangement of atoms in solids. It is a vast and interdisciplinary field that has applications in physics, chemistry, materials science, biology, and engineering.\n",
      "\n",
      "The structure factor is a mathematical function that is used to describe the diffraction of waves by a crystal. It is a complex number that is related to the atomic positions in the crystal.\n",
      "\n",
      "The structure factor can be used to calculate the intensity of the diffracted waves. This information can be used to determine the atomic positions in the crystal and to study the structure of materials.\n",
      "\n",
      "Crystallography is a powerful tool for understanding the structure of materials. It has been used to determine the structures of many important materials, including metals, semiconductors, and pharmaceuticals. It is also used to study the structure of biological materials, such as proteins and DNA.\n",
      "\n",
      "The structure factor is a key concept in crystallography. It is used to describe the diffraction of waves by a crystal and to calculate the intensity of the diffracted waves. This information can be used to determine the atomic positions in the crystal and to study the structure of materials.\n"
     ]
    }
   ],
   "source": [
    "print(train_ds4_processed[0]['input_text'])\n",
    "print(train_ds4_processed[0]['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684a568",
   "metadata": {},
   "source": [
    "### ultrachat-200k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3af94d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_example(example):\n",
    "    messages = example['messages']\n",
    "    _,input_text = create_chat_text(tokenizer, messages[0]['content'])\n",
    "    return {\"input_text\":input_text, \"output_text\":messages[1]['content']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30de8364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 4.44k/4.44k [00:00<00:00, 9.05MB/s]\n",
      "Downloading data: 100%|██████████| 244M/244M [00:01<00:00, 211MB/s]  \n",
      "Downloading data: 100%|██████████| 244M/244M [00:01<00:00, 211MB/s]  \n",
      "Downloading data: 100%|██████████| 244M/244M [00:01<00:00, 217MB/s]  \n",
      "Downloading data: 100%|██████████| 81.2M/81.2M [00:00<00:00, 188MB/s] \n",
      "Downloading data: 100%|██████████| 244M/244M [00:01<00:00, 213MB/s]  \n",
      "Downloading data: 100%|██████████| 243M/243M [00:01<00:00, 211MB/s]  \n",
      "Downloading data: 100%|██████████| 243M/243M [00:01<00:00, 194MB/s]  \n",
      "Downloading data: 100%|██████████| 80.4M/80.4M [00:00<00:00, 183MB/s] \n",
      "Generating train_sft split: 100%|██████████| 207865/207865 [00:06<00:00, 32004.72 examples/s]\n",
      "Generating test_sft split: 100%|██████████| 23110/23110 [00:00<00:00, 42637.06 examples/s]\n",
      "Generating train_gen split: 100%|██████████| 256032/256032 [00:06<00:00, 42278.84 examples/s]\n",
      "Generating test_gen split: 100%|██████████| 28304/28304 [00:00<00:00, 56562.58 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'prompt_id', 'messages'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds5 = load_dataset('HuggingFaceH4/ultrachat_200k', name='default')\n",
    "train_ds5 = train_ds5['train_sft'].shuffle(42).select(range(10000))\n",
    "train_ds5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e15c1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:02<00:00, 4647.41 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds5_processed = train_ds5.map(process_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bcb026b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds5_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42891290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful AI assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "How does the location of the Sydney Conservatorium of Music impact the academic and professional opportunities available to music students, and how does the conservatorium support student engagement with the music industry in Australia?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "The location of the Sydney Conservatorium of Music, which is situated in the heart of Sydney's cultural precinct, impacts both the academic and professional opportunities available to music students. The conservatorium is located near several major performing arts venues and organizations, including the Sydney Opera House, the Australian Broadcasting Corporation, and the Sydney Symphony Orchestra, providing students with easy access to performances, rehearsals, and networking opportunities.\n",
      "\n",
      "One of the primary ways the conservatorium supports student engagement with the music industry in Australia is through its strong industry connections. The conservatorium has established partnerships with numerous professional music organizations, such as the Australian Chamber Orchestra, Opera Australia, and the Melbourne Symphony Orchestra. These partnerships provide students with the opportunity to work with industry professionals and gain practical experience in their chosen field.\n",
      "\n",
      "The conservatorium also offers a range of academic and extra-curricular programs that prepare students for careers in the music industry. For example, the Bachelor of Music (Performance) program includes specialized pathways in instrumental/vocal performance, composition, and musicology, while the Artist-In-Residence program allows students to work with internationally renowned musicians.\n",
      "\n",
      "Additionally, the conservatorium has a dedicated Career Development Office that provides students with assistance in finding employment, internships, and performance opportunities. The office also hosts regular industry events, such as masterclasses and networking sessions, to help students connect with industry professionals and gain a deeper understanding of the music industry in Australia.\n",
      "\n",
      "Overall, the location of the Sydney Conservatorium of Music and its strong industry connections provide students with a range of academic and professional opportunities that prepare them for successful careers in the music industry.\n"
     ]
    }
   ],
   "source": [
    "print(train_ds5_processed[0]['input_text'])\n",
    "print(train_ds5_processed[0]['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767f61f9",
   "metadata": {},
   "source": [
    "### open hermes 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c897a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_example(example):\n",
    "    messages = example['conversations']\n",
    "    _,input_text = create_chat_text(tokenizer, messages[0]['value'])\n",
    "    return {\"input_text\":input_text, \"output_text\":messages[1]['value']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ef29c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 4.75k/4.75k [00:00<00:00, 11.8MB/s]\n",
      "Downloading data: 100%|██████████| 1.94G/1.94G [00:07<00:00, 245MB/s] \n",
      "Generating train split: 100%|██████████| 1001551/1001551 [00:22<00:00, 45143.64 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds6 = load_dataset('teknium/OpenHermes-2.5')\n",
    "train_ds6 = train_ds6['train'].shuffle(42).select(range(10000))\n",
    "train_ds6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6171a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:02<00:00, 3748.61 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds6_processed = train_ds6.map(process_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6dcdbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds6_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e07464b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful AI assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "A Sierpinski arrowhead curve is created by dividing an equilateral triangle into three smaller equilateral triangles and removing the central one, then doing the same for each remaining smaller triangle. If the length of the original triangle is 6cm, what is the perimeter of the Sierpinski arrowhead curve after the third iteration?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "After each iteration, the perimeter of the Sierpinski arrowhead curve increases by a factor of 2. Let's calculate the perimeter after the third iteration:\n",
      "\n",
      "1st iteration:\n",
      "Perimeter = 6 cm * 2 = 12 cm\n",
      "\n",
      "2nd iteration:\n",
      "Perimeter = 12 cm * 2 = 24 cm\n",
      "\n",
      "3rd iteration:\n",
      "Perimeter = 24 cm * 2 = 48 cm\n",
      "\n",
      "So, the perimeter of the Sierpinski arrowhead curve after the third iteration is 48 cm.\n"
     ]
    }
   ],
   "source": [
    "print(train_ds6_processed[0]['input_text'])\n",
    "print(train_ds6_processed[0]['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e21abc",
   "metadata": {},
   "source": [
    "### starcoder-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3dbc7e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_example(example):\n",
    "    _,input_text = create_chat_text(tokenizer, example['prompt'])\n",
    "    return {\"input_text\":input_text, \"output_text\":example['response']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "810e4845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 922/922 [00:00<00:00, 2.62MB/s]\n",
      "Downloading data: 100%|██████████| 90.1M/90.1M [00:00<00:00, 126MB/s] \n",
      "Generating train split: 100%|██████████| 50661/50661 [00:00<00:00, 89854.26 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['fingerprint', 'sha1', 'seed', 'response', 'concepts', 'prompt', 'instruction', 'id'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds7 = load_dataset('bigcode/self-oss-instruct-sc2-exec-filter-50k')\n",
    "train_ds7 = train_ds7['train'].shuffle(42).select(range(10000))\n",
    "train_ds7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32d5cc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:01<00:00, 5161.56 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds7_processed = train_ds7.map(process_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be4dc0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds7_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fd97968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful AI assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Provide the best response to a given instruction. Follow the following steps to craft your response:\n",
      "1. reason about the given instruction\n",
      "2. provide a high-quality solution\n",
      "3. offer a concise explanation\n",
      "4. write tests to verify the correctness your solution\n",
      "\n",
      "## Example 1\n",
      "### Instruction\n",
      "Design a Python function that takes a sorted array and a target value, and return a valid index where target can be inserted to maintain the array's sorted order. Optimize the function to run in logarithmic time complexity.\n",
      "\n",
      "For example, given `array = [1, 3, 5, 5, 6]` and `target = 5`, the function should return either 2 or 3 because 5 presents at both indices 2 and 3.\n",
      "\n",
      "### Response\n",
      "[Reasoning]\n",
      "To solve this problem efficiently and ensure logarithmic time complexity, we can use a binary search algorithm. Compared with a standard binary search that looks for an exact match, we can modify the algorithm such that when the target is not found, we return the `left` bound, which represents the index where the target can be inserted to maintain the array's sorted order. Since any valid index for insertion is acceptable, we can direclty return the index if there is an exact match.\n",
      "\n",
      "[Implementation]\n",
      "Here is a Python function that implements this approach:\n",
      "\n",
      "```python\n",
      "from typing import List\n",
      "\n",
      "def search_insert_position(nums: List[int], target: int) -> int:\n",
      "    \"\"\"\n",
      "    Finds the index to insert `target` into `nums` to maintain sorted order. For example,\n",
      "    given `nums = [1, 3, 5, 5, 6]` and `target = 5`, this function returns either 2 or 3,\n",
      "    as `target` can be inserted at index 2 or 3 to maintain the sorted order.\n",
      "    \"\"\"\n",
      "    left, right = 0, len(nums) - 1\n",
      "\n",
      "    while left <= right:\n",
      "        mid = (left + right) // 2\n",
      "\n",
      "        # Directly return the index if there's an exact match\n",
      "        if nums[mid] == target:\n",
      "            return mid\n",
      "        elif nums[mid] < target:\n",
      "            left = mid + 1\n",
      "        else:\n",
      "            right = mid - 1\n",
      "\n",
      "    # At this point, `left` is the correct insertion index\n",
      "    return left\n",
      "```\n",
      "\n",
      "[Explanation]\n",
      "This implementation ensures that when `target` is not found, `left` represents the correct insertion index. This is because at the end of the loop, all elements to the left of `left` are smaller than `target`, all elements to the right of `left` are equal to or larger than `target`, and `left > right`. Therefore, `left` is the correct index for insertion to maintain the sorted order.\n",
      "\n",
      "[Tests]\n",
      "To test this function, you can use the example you provided:\n",
      "\n",
      "```python\n",
      "# Provided example\n",
      "assert search_insert_position([1, 3, 5, 5, 6], 5) in [2, 3]\n",
      "# Additional cases\n",
      "assert search_insert_position([1, 3, 5, 5, 6], 2) == 1\n",
      "assert search_insert_position([1, 3, 5, 5, 6], 7) == 5\n",
      "```\n",
      "\n",
      "These tests cover the scenario where the target is found at multiple indices, as well as cases where the target is not present in the array but needs to be inserted at the correct position to maintain the sorted order.\n",
      "\n",
      "## Example 2\n",
      "### Instruction\n",
      "Define a Python function that takes a list of objects and returns a list of dictionaries representing the objects. Each dictionary should have the object's class name as key, and a list of dictionaries representing the object's attributes as value. Each attribute dictionary should have the attribute name as key and the attribute value as value. The function should use dynamic class construction and object serialization.\n",
      "\n",
      "### Response<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "Here is a Python function that implements this approach:\n",
      "\n",
      "```python\n",
      "def serialize_objects(objects):\n",
      "    \"\"\"\n",
      "    Serialize a list of objects into a list of dictionaries.\n",
      "    Each dictionary represents the object's class name and attributes.\n",
      "    \"\"\"\n",
      "    serialized_objects = []\n",
      "    for obj in objects:\n",
      "        serialized_object = {\n",
      "            \"class_name\": obj.__class__.__name__,\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "        for attr_name, attr_value in obj.__dict__.items():\n",
      "            attr_dict = serialize_value(attr_value)\n",
      "            serialized_object[\"attributes\"][attr_name] = attr_dict\n",
      "        serialized_objects.append(serialized_object)\n",
      "    return serialized_objects\n",
      "\n",
      "def serialize_value(value):\n",
      "    \"\"\"\n",
      "    Serialize a value into a dictionary.\n",
      "    \"\"\"\n",
      "    if isinstance(value, list):\n",
      "        serialized_value = [serialize_value(item) for item in value]\n",
      "    elif isinstance(value, dict):\n",
      "        serialized_value = {key: serialize_value(value) for key, value in value.items()}\n",
      "    else:\n",
      "        serialized_value = value\n",
      "    return serialized_value\n",
      "```\n",
      "\n",
      "This implementation uses dynamic class construction to create a dictionary for each object in the list, and then uses object serialization to convert the object's attributes into a dictionary. The `serialize_value` function is used recursively to serialize any nested lists or dictionaries.\n"
     ]
    }
   ],
   "source": [
    "print(train_ds7_processed[0]['input_text'])\n",
    "print(train_ds7_processed[0]['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f7c5e9",
   "metadata": {},
   "source": [
    "### The Tome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20e56f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_example(example):\n",
    "    messages = example['conversations']\n",
    "    _,input_text = create_chat_text(tokenizer, messages[0]['value'])\n",
    "    return {\"input_text\":input_text, \"output_text\":messages[1]['value']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 1.75k/1.75k [00:00<00:00, 5.69MB/s]\n",
      "Downloading data: 100%|██████████| 4.58G/4.58G [00:23<00:00, 196MB/s] \n",
      "Generating train split: 100%|██████████| 1752473/1752473 [00:07<00:00, 235702.00 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversations', 'dataset'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds8 = load_dataset('arcee-ai/The-Tome')\n",
    "train_ds8 = train_ds8['train'].shuffle(42).select(range(10000))\n",
    "train_ds8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1374edaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:01<00:00, 5854.94 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds8_processed = train_ds8.map(process_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ac571d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds8_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e6f1b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful AI assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Google’s recent announcement to create 10,000 new jobs in Europe, 6,000 of which will be in the UK, has been welcomed by the Business Secretary. What is the main focus of Google's expansion in Europe and how does it impact the economies of the countries it operates in?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "Google's recent announcement to create 10,000 new jobs in Europe, with 6,000 of those positions located in the UK, is a significant development that has been welcomed by the Business Secretary. This expansion is primarily focused on bolstering Google's presence in key areas such as engineering, sales, and marketing, as well as in new initiatives like artificial intelligence and cloud computing.\n",
      "\n",
      "The impact of this expansion on the economies of the countries it operates in is multifaceted:\n",
      "\n",
      "1. **Job Creation**: The creation of 10,000 new jobs directly contributes to reducing unemployment rates and stimulating local economies. These positions often come with competitive salaries and benefits, which can lead to increased consumer spending and economic growth.\n",
      "\n",
      "2. **Skill Development and Training**: Google's presence often encourages the development of local talent through training programs and partnerships with educational institutions. This not only enhances the skills of the workforce but also fosters a culture of innovation and technology adoption.\n",
      "\n",
      "3. **Economic Diversification**: By investing in sectors like AI and cloud computing, Google helps diversify the economies of the countries it operates in. This diversification can reduce reliance on traditional industries and make economies more resilient to global economic fluctuations.\n",
      "\n",
      "4. **Increased Tax Revenue**: The influx of new employees leads to higher tax revenues for the government, which can be used to fund public services, infrastructure, and other economic development initiatives.\n",
      "\n",
      "5. **Boost to Local Businesses**: Google's operations often lead to a multiplier effect, benefiting local businesses through increased demand for goods and services. This can include everything from office supplies to catering services, contributing to a broader economic ecosystem.\n",
      "\n",
      "6. **International Investment**: Google's decision to expand in Europe signals confidence in the region's economic stability and potential for growth. This can attract further investment from other companies, enhancing the attractiveness of the region as a business hub.\n",
      "\n",
      "7. **Cultural and Technological Exchange**: The presence of a global tech giant like Google can facilitate the exchange of ideas and technologies, contributing to the development of local tech ecosystems and fostering a more connected and innovative community.\n",
      "\n",
      "Overall, Google's expansion in Europe is expected to have a positive impact on the economies of the countries involved, driving growth, creating jobs, and promoting technological advancement.\n"
     ]
    }
   ],
   "source": [
    "print(train_ds8_processed[0]['input_text'])\n",
    "print(train_ds8_processed[0]['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061de6e1",
   "metadata": {},
   "source": [
    "### openhermes 200k unfiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d34b2ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_example(example):\n",
    "    messages = example['conversations']\n",
    "    _,input_text = create_chat_text(tokenizer, messages[0]['value'])\n",
    "    return {\"input_text\":input_text, \"output_text\":messages[1]['value']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f4403df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 31.0/31.0 [00:00<00:00, 127kB/s]\n",
      "Downloading data: 100%|██████████| 335M/335M [00:01<00:00, 179MB/s]  \n",
      "Generating train split: 100%|██████████| 184892/184892 [00:00<00:00, 288737.74 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversations', 'relevance_score', 'id'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds9 = load_dataset(\"Crystalcareai/openhermes_200k_unfiltered\")\n",
    "train_ds9 = train_ds9['train'].sort(\"relevance_score\").select(range(10000))\n",
    "train_ds9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7097246f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:01<00:00, 5748.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds9_processed = train_ds9.map(process_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c019658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds9_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed62cb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful AI assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "If a company produces 5000 units of a product per day and sells them for $20 each, how much additional revenue would they generate if they increased their production by 10%?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "First, let's calculate the current daily revenue generated by selling 5000 units at $20 each:\n",
      "\n",
      "Current daily revenue = Units sold * Price per unit\n",
      "                                  = 5000 * $20\n",
      "                                  = $100,000\n",
      "\n",
      "Now, we need to find out how many additional units will be produced if the company increases its production by 10%. To do this, we multiply the current production (5000 units) by 10%:\n",
      "\n",
      "Additional units = Current production * 10%\n",
      "                            = 5000 * 0.1\n",
      "                            = 500 units\n",
      "\n",
      "So, the company will produce an additional 500 units per day.\n",
      "\n",
      "Next, we need to calculate the additional revenue generated from selling these extra 500 units at $20 each:\n",
      "\n",
      "Additional revenue = Additional units * Price per unit\n",
      "                             = 500 * $20\n",
      "                             = $10,000\n",
      "\n",
      "Therefore, if the company increases its production by 10%, it would generate an additional $10,000 in daily revenue.\n"
     ]
    }
   ],
   "source": [
    "print(train_ds9_processed[0]['input_text'])\n",
    "print(train_ds9_processed[0]['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96115d75",
   "metadata": {},
   "source": [
    "### Synth reasoning alpaca combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4510ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_example(example):\n",
    "    _,input_text = create_chat_text(tokenizer, example['instruction'])\n",
    "    return {\"input_text\":input_text, \"output_text\":example['output']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "854b74af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 4.20M/4.20M [00:00<00:00, 14.8MB/s]\n",
      "Generating train split: 100%|██████████| 11000/11000 [00:00<00:00, 428610.46 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'output'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds10 = load_dataset(\"Crystalcareai/synthetic_reasoning_natural_Alpaca_Combined\")\n",
    "train_ds10 = train_ds10['train'].shuffle(42).select(range(1000))\n",
    "train_ds10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38c98191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7487.98 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds10_processed = train_ds10.map(process_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87583a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds10_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0442e6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful AI assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "If Bob is hot, then Bob is big.\n",
      "If Bob is cold, then Bob is bad.\n",
      "If Bob is slow and blue, then Bob is beautiful.\n",
      "If person is round, then person is clean.\n",
      "If Bob is strong, then Bob is happy.\n",
      "Fact:\n",
      "Bob is nice and cool.\n",
      "The following can be determined about Bob:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "Bob is bad.\n"
     ]
    }
   ],
   "source": [
    "print(train_ds10_processed[0]['input_text'])\n",
    "print(train_ds10_processed[0]['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67197f2a",
   "metadata": {},
   "source": [
    "### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f534d8d-7960-4a1b-a9b6-cc927c5e74e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_train_ds = concatenate_datasets([train_ds1_processed.select_columns(['input_text', 'output_text']), \n",
    "                                        train_ds2_processed.select_columns(['input_text', 'output_text']), \n",
    "                                        train_ds3_processed.select_columns(['input_text', 'output_text']),\n",
    "                                        train_ds4_processed.select_columns(['input_text', 'output_text']),\n",
    "                                        train_ds5_processed.select_columns(['input_text', 'output_text']), \n",
    "                                        train_ds6_processed.select_columns(['input_text', 'output_text']),\n",
    "                                        train_ds7_processed.select_columns(['input_text', 'output_text']),\n",
    "                                        train_ds8_processed.select_columns(['input_text', 'output_text']), \n",
    "                                        train_ds9_processed.select_columns(['input_text', 'output_text']),\n",
    "                                        train_ds10_processed.select_columns(['input_text', 'output_text'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db49791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_train_ds = concat_train_ds.shuffle(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a506d9c6-a722-47f6-8b6b-46de80feea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 90846/90846 [00:00<00:00, 155261.29 examples/s]\n"
     ]
    }
   ],
   "source": [
    "concat_train_ds.save_to_disk(\"/workspace/data/llama_large_mix_dataset_v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "70562ccc-17b6-494b-8ed1-8a14e3f84744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tokenize(exs):\n",
    "    return {\"input_token_ids\" : tokenizer(exs['input_text'])['input_ids'],\n",
    "            \"output_token_ids\" : tokenizer(exs['output_text'])['input_ids']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "497017d0-c564-4173-9353-14091e155b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 90846/90846 [00:24<00:00, 3652.50 examples/s]\n"
     ]
    }
   ],
   "source": [
    "concat_train_ds = concat_train_ds.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "43dcb5b8-2d35-45a4-9c13-ba89d836bb34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def token_lenghts(ex):\n",
    "    return {\"token_length\": len(ex['input_token_ids']) + len(ex['output_token_ids'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "80f39266-84af-4c78-b603-81b7c47b8d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 90846/90846 [00:24<00:00, 3772.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "concat_train_ds = concat_train_ds.map(token_lenghts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d3f99f1-31de-4f8a-a210-7ff677e642be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1190664/2679568758.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  pd.value_counts(concat_train_ds['token_length'], normalize=True, bins=10).sort_index().cumsum()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22.483999999999998, 478.5]    0.671279\n",
       "(478.5, 930.0]                 0.898785\n",
       "(930.0, 1381.5]                0.990996\n",
       "(1381.5, 1833.0]               0.998437\n",
       "(1833.0, 2284.5]               0.999362\n",
       "(2284.5, 2736.0]               0.999692\n",
       "(2736.0, 3187.5]               0.999769\n",
       "(3187.5, 3639.0]               0.999868\n",
       "(3639.0, 4090.5]               0.999912\n",
       "(4090.5, 4542.0]               1.000000\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(concat_train_ds['token_length'], normalize=True, bins=10).sort_index().cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6110d98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 90846/90846 [00:15<00:00, 6036.02 examples/s]\n"
     ]
    }
   ],
   "source": [
    "concat_train_filtered_ds = concat_train_ds.filter(lambda ex: ex[\"token_length\"] < 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d2c9a9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_text', 'output_text', 'input_token_ids', 'output_token_ids', 'token_length'],\n",
       "    num_rows: 84289\n",
       "})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_train_filtered_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fdb983f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 84289/84289 [00:00<00:00, 122879.25 examples/s]\n"
     ]
    }
   ],
   "source": [
    "concat_train_filtered_ds.save_to_disk(\"/workspace/data/llama_large_mix_dataset_v0_1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5c39c7-7d59-42e5-82fd-68a304ef216e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
