{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78ebc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "import gspread\n",
    "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5219bb",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c3dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {\"model_name\":\"meta-llama/Llama-2-7b-hf\", \"model_size\":7}, \n",
    "    {\"model_name\":\"meta-llama/Llama-2-13b-hf\", \"model_size\":13},\n",
    "    {\"model_name\":\"codellama/CodeLlama-34b-hf\", \"model_size\":34},\n",
    "    {\"model_name\":\"meta-llama/Llama-2-70b-hf\", \"model_size\":70}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f3d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for m in models:\n",
    "#     cfg = AutoConfig.from_pretrained(m['model_name'])\n",
    "#     m['config'] = cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen = [{\"seqlen\":256}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2f8d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_bs = [{\"max_bs\":None}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d25c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = [{\"bs\":None}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6defaf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_offloading = [{\"cpu_offloading\":False}, {\"cpu_offloading\":True}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564866c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "distrib_type = [{\"distrib_type\":\"FSDP\"}, {\"distrib_type\":\"DDP\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03572dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_type = [{\"ft_type\":\"LoRA\"}, {\"ft_type\":\"QLoRA\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdd62fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RTX 3090 is not available in cloud providers A5000 also has 24GB memory\n",
    "gpus = [{\"gpu_model\":\"A5000\", \"num_gpus\":2, \"gpu_mem\":24, \"total_gpu_mem\":48, \"nvlink\":\"False\"},\n",
    "        {\"gpu_model\":\"A100-40\", \"num_gpus\":8, \"gpu_mem\":40, \"total_gpu_mem\":320, \"nvlink\":\"True\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f1386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb = [{\"wandb_link\":None,\n",
    "          \"memory_peak\":None, \n",
    "          \"memory_after_model_creation\":None,\n",
    "          \"memory_after_model_wrap\":None,          \n",
    "          \"memory_before_forward\":None,\n",
    "          \"memory_after_forward\":None,\n",
    "          \"memory_before_backward\":None,\n",
    "          \"memory_after_backward\":None, \n",
    "          \"time_taken\":None}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d394429",
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = [models, seqlen, max_bs, bs, cpu_offloading, distrib_type, ft_type, gpus, wandb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fab4270",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = list(itertools.product(*iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f2f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cad6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list_of_dicts(l):\n",
    "    final_d = {}\n",
    "    for d in l: \n",
    "        for k,v in d.items():\n",
    "            if k in final_d:\n",
    "                raise ValueError(f\"Key {k} exists.\")\n",
    "            final_d[k] = v\n",
    "    return final_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a910744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_flat = [flatten_list_of_dicts(exp) for exp in experiments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606c605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(experiments_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b6c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude lora ddp\n",
    "mask = ~((df['ft_type'] == 'LoRA') & (df['distrib_type'] == 'DDP'))\n",
    "# no cpu-offloading with ddp\n",
    "mask = np.logical_and(mask, ~((df['cpu_offloading'] == True) & (df['distrib_type'] == 'DDP')))\n",
    "\n",
    "df = df[mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd687cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8770de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d625f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gspread\n",
    "# !pip install gspread-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d56abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = gspread.oauth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a00615",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://docs.google.com/spreadsheets/d/1JSQbnkwtqPgc-_wqI3LTCJI6jWCaWafubK0ontWR2_Y\"\n",
    "sheet = gc.open_by_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad54f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will overwrite the existing sheet!\n",
    "# use other utils from gspread to add data to specific cells.\n",
    "worksheet = sheet.get_worksheet_by_id(0)\n",
    "set_with_dataframe(worksheet, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8213e2ab",
   "metadata": {},
   "source": [
    "### Modify Experiments\n",
    "\n",
    "Flag experiments based on the theoretical limits excluding the activations.\n",
    "\n",
    "**Note:** In DDP script cast all model params to bfloat16 except for RoPE layers.\n",
    "\n",
    "1) DDP requires all params, optimizer states, activations to fit into a single GPU.\n",
    "\n",
    "2) Compute approx memory requirement per GPU with FSDP full sharing, consider cases with and without CPU offloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fad2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://docs.google.com/spreadsheets/d/1JSQbnkwtqPgc-_wqI3LTCJI6jWCaWafubK0ontWR2_Y\"\n",
    "sheet = gc.open_by_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f9835",
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet = sheet.get_worksheet_by_id(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6dbda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = worksheet.get_all_values()\n",
    "df = pd.DataFrame(vals[1:], columns=vals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ffe007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35082b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a8b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "oom_ignored = []\n",
    "for row in df.itertuples():\n",
    "    # approx mem req with AdamW is x4 model size (FSDP uses full shard)\n",
    "    if row.cpu_offloading != 'TRUE':\n",
    "        approx_mem_req = int(row.model_size) * 2 * 4 / (int(row.num_gpus) if row.distrib_type == 'FSDP' else 1)\n",
    "        oom_ignored.append(approx_mem_req > int(row.total_gpu_mem))\n",
    "    else:\n",
    "        oom_ignored.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638b97e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['oom_ignored'] = oom_ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc63ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_with_dataframe(worksheet, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d03fc85",
   "metadata": {},
   "source": [
    "### Create Training Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2466f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850ed294",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df.query(\"~oom_ignored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113fff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_gpu_commands = []\n",
    "large_gpu_commands = []\n",
    "\n",
    "for _, row in sub_df.iterrows():\n",
    "    cmd_args = [\"python train.py\",\n",
    "        \"--batch_size 128\", # divide by 2 every retry\n",
    "        \"--num_epochs 1\",\n",
    "        \"--dataset alpaca_sample\",\n",
    "        \"--use_flash_attention\",\n",
    "        \"--precision bf16\",\n",
    "        \"--mp_bf16_mode mixed\",\n",
    "        \"--log_to wandb\",\n",
    "    ]\n",
    "\n",
    "    if row.distrib_type == \"DDP\":\n",
    "        cmd_args.append(\"--use_dpp\")\n",
    "    elif row.distrib_type == \"FSDP\":\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown distrib_type {distrib_type}\")\n",
    "\n",
    "    cmd_args.append(f\"--model_name {row.model_name}\")\n",
    "\n",
    "    cmd_args.append(f\"--context_length {row.seqlen}\")\n",
    "\n",
    "    if row.cpu_offloading == \"TRUE\":\n",
    "        cmd_args.append(\"--use_cpu_offload\")\n",
    "\n",
    "    if row.ft_type == \"LoRA\":\n",
    "        cmd_args.append(\"--train_type lora\")\n",
    "    elif row.ft_type == \"QLoRA\":\n",
    "        cmd_args.append(\"--train_type qlora\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown ft_type {ft_type}\")\n",
    "        \n",
    "    if row.gpu_model == \"A100-40\":\n",
    "        large_gpu_commands.append(\" \".join(cmd_args))\n",
    "    elif row.gpu_model == \"A5000\":\n",
    "        small_gpu_commands.append(\" \".join(cmd_args))\n",
    "    else:\n",
    "        ValueError(\"Unknown gpu model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45cc821",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../benchmarking\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb58d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../benchmarking/small_gpu_benchmarking.sh\", \"w\") as f: \n",
    "    f.write(\"\\n\".join(small_gpu_commands))\n",
    "\n",
    "with open(\"../benchmarking/large_gpu_benchmarking.sh\", \"w\") as f: \n",
    "    f.write(\"\\n\".join(large_gpu_commands))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b6c07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_dataset(\"yahma/alpaca-cleaned\", split=\"train[:1024]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911f8165",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9745dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97298ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1df75af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d0442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0894216f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766a2172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126085a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e268230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b7b240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
