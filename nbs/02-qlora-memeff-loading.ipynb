{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56c7c28c-651d-40d9-9989-84d5e0acd6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/git/bitsandbytes/bitsandbytes/cuda_setup/main.py:109: UserWarning: \n",
      "\n",
      "================================================================================\n",
      "WARNING: Manual override via BNB_CUDA_VERSION env variable detected!\n",
      "BNB_CUDA_VERSION=XXX can be used to load a bitsandbytes version that is different from the PyTorch CUDA version.\n",
      "If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=\n",
      "If you use the manual override make sure the right libcudart.so is in your LD_LIBRARY_PATH\n",
      "For example by adding the following to your .bashrc: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:<path_to_cuda_dir/lib64\n",
      "Loading CUDA version: BNB_CUDA_VERSION=123\n",
      "================================================================================\n",
      "\n",
      "\n",
      "  warn((f'\\n\\n{\"=\"*80}\\n'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import bitsandbytes as bnb\n",
    "import safetensors\n",
    "from safetensors.torch import save_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60ce68e7-7a82-4bce-a6f5-c1222ac9595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitsandbytes.nn import Linear4bit, Params4bit\n",
    "import bitsandbytes.functional as F\n",
    "from transformers.utils import hub, SAFE_WEIGHTS_NAME, SAFE_WEIGHTS_INDEX_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7c0725d-dbda-455d-a02c-32b6f489229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b863ae30-fa93-4bf7-9010-a73b972c63b2",
   "metadata": {},
   "source": [
    "### Custom QLORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "021e2cfd-a23e-4978-831b-34c82e7b1910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_linear(model, linear_replacement, skip_modules=[\"lm_head\"], **kwargs):\n",
    "    \"\"\"\n",
    "    Replace linear modules with a new Linear module.\n",
    "    Parameters:\n",
    "        model (`torch.nn.Module`):\n",
    "            Input model or `torch.nn.Module` as the function is run recursively.\n",
    "        linear_replacement (`torch.nn.Module`):\n",
    "            The linear module that replaces the old one. Only expects standard arguments.\n",
    "            If other arguments need to be passed, use a lambda.\n",
    "        skip_modules (`List[str]`, *optional*, defaults to `lm_head`):\n",
    "            List of modules names not to convert. Defaults to `lm_head`.\n",
    "    \"\"\"\n",
    "    for name, module in model.named_children():\n",
    "        if len(list(module.children())) > 0:\n",
    "            replace_linear(module, linear_replacement, skip_modules, **kwargs)\n",
    "\n",
    "        if isinstance(module, torch.nn.Linear) and name not in skip_modules:\n",
    "            model._modules[name] = linear_replacement(\n",
    "                module.in_features,\n",
    "                module.out_features,\n",
    "                module.bias is not None,\n",
    "                **kwargs\n",
    "            )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11866a8d-a38a-4db0-83ac-dceaa7623872",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['lora_rank']: int = 64 # LoRA rank for lora/qlora\n",
    "args['lora_alpha']: int = 16 # LoRA alpha for lora/qlora\n",
    "args['lora_dropout']: float = 0.1 # LoRA dropout for lora/qlora\n",
    "args['lora_target_modules'] = \"all\" #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d5dbaf26-8937-4721-a905-ee2ce893e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLORA(nn.Module):\n",
    "    def __init__(self, base_layer, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.base_layer = base_layer\n",
    "        dtype = base_layer.compute_dtype\n",
    "        self.lora_A = nn.Linear(base_layer.weight.shape[0], args[\"lora_rank\"], bias=False, device=device, dtype=dtype)\n",
    "        self.lora_B = nn.Linear(args[\"lora_rank\"], base_layer.weight.shape[1], bias=False, device=device, dtype=dtype)\n",
    "        self.lora_alpha = args[\"lora_alpha\"]\n",
    "        self.lora_dropout = nn.Dropout(args[\"lora_dropout\"])\n",
    "        self.scaling = self.lora_alpha / args['lora_rank']\n",
    "\n",
    "        for p in self.lora_A.parameters():\n",
    "            p.requires_grad = True\n",
    "        for p in self.lora_B.parameters():\n",
    "            p.requires_grad = True\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, *args, **kwargs) -> torch.Tensor:\n",
    "\n",
    "        result = self.base_layer(x, *args, **kwargs)\n",
    "        # As per Tim Dettmers, for 4bit, we need to defensively clone here.\n",
    "        # The reason is that in some cases, an error can occur that backprop\n",
    "        # does not work on a manipulated view. This issue may be solved with\n",
    "        # newer PyTorch versions but this would need extensive testing to be\n",
    "        # sure.\n",
    "        result = result.clone()\n",
    "\n",
    "        requires_conversion = not torch.is_autocast_enabled()\n",
    "        if requires_conversion:\n",
    "            expected_dtype = result.dtype\n",
    "            x = x.to(self.lora_A.weight.dtype)\n",
    "\n",
    "        output = self.lora_B(self.lora_A(self.lora_dropout(x)))\n",
    "        if requires_conversion:\n",
    "            output = output.to(expected_dtype)\n",
    "        output = output * self.scaling\n",
    "        result += output\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b73de19-d8d5-42dc-9e80-f80bb5782064",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = AutoConfig.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "cfg.use_cache = False\n",
    "cfg._attn_implementation = \"flash_attention_2\"\n",
    "cfg.update(dict(num_hidden_layers=2)) # debug mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c3862442-774f-4fae-81b5-63323b153bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eca3743a-6ed2-46c3-975c-604903c48ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "99eea60e-79fe-4ee2-9fa8-acefad2c7029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): QLORA(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (lora_A): Linear(in_features=4096, out_features=64, bias=False)\n",
       "            (lora_B): Linear(in_features=64, out_features=4096, bias=False)\n",
       "            (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (k_proj): QLORA(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (lora_A): Linear(in_features=4096, out_features=64, bias=False)\n",
       "            (lora_B): Linear(in_features=64, out_features=4096, bias=False)\n",
       "            (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (v_proj): QLORA(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (lora_A): Linear(in_features=4096, out_features=64, bias=False)\n",
       "            (lora_B): Linear(in_features=64, out_features=4096, bias=False)\n",
       "            (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): QLORA(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "            (lora_A): Linear(in_features=11008, out_features=64, bias=False)\n",
       "            (lora_B): Linear(in_features=64, out_features=4096, bias=False)\n",
       "            (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (up_proj): QLORA(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "            (lora_A): Linear(in_features=11008, out_features=64, bias=False)\n",
       "            (lora_B): Linear(in_features=64, out_features=4096, bias=False)\n",
       "            (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (down_proj): QLORA(\n",
       "            (base_layer): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
       "            (lora_A): Linear(in_features=4096, out_features=64, bias=False)\n",
       "            (lora_B): Linear(in_features=64, out_features=11008, bias=False)\n",
       "            (lora_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7894979c-e6a1-44f6-9e4a-a476cad64ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model = replace_linear(model.model, Linear4bit, compute_dtype=torch.bfloat16,\n",
    "                             quant_type='nf4', quant_storage=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "658f8112-d48c-45d2-aa49-ee8adb22cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_target_modules = [\"k_proj\", \"q_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"gate_proj\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6a4d0db9-a88c-4a14-a55b-a3488b53ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,module in model.named_modules():\n",
    "    module_key, _, value_key = name.rpartition('.')\n",
    "    if value_key in lora_target_modules:\n",
    "        m = model.get_submodule(name)\n",
    "        qlora_layer = QLORA(m)\n",
    "        parent_module = model.get_submodule(module_key)\n",
    "        setattr(parent_module, value_key, qlora_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "98de1bff-9343-4fca-8360-adadfda87dce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbase_layer\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'base_layer' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a6463e0d-c24c-4ffe-b8e2-625bbf68754f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight False\n",
      "model.layers.0.self_attn.q_proj.base_layer.weight False\n",
      "model.layers.0.self_attn.q_proj.lora_A.weight True\n",
      "model.layers.0.self_attn.q_proj.lora_B.weight True\n",
      "model.layers.0.self_attn.k_proj.base_layer.weight False\n",
      "model.layers.0.self_attn.k_proj.lora_A.weight True\n",
      "model.layers.0.self_attn.k_proj.lora_B.weight True\n",
      "model.layers.0.self_attn.v_proj.base_layer.weight False\n",
      "model.layers.0.self_attn.v_proj.lora_A.weight True\n",
      "model.layers.0.self_attn.v_proj.lora_B.weight True\n",
      "model.layers.0.self_attn.o_proj.weight False\n",
      "model.layers.0.mlp.gate_proj.base_layer.weight False\n",
      "model.layers.0.mlp.gate_proj.lora_A.weight True\n",
      "model.layers.0.mlp.gate_proj.lora_B.weight True\n",
      "model.layers.0.mlp.up_proj.base_layer.weight False\n",
      "model.layers.0.mlp.up_proj.lora_A.weight True\n",
      "model.layers.0.mlp.up_proj.lora_B.weight True\n",
      "model.layers.0.mlp.down_proj.base_layer.weight False\n",
      "model.layers.0.mlp.down_proj.lora_A.weight True\n",
      "model.layers.0.mlp.down_proj.lora_B.weight True\n",
      "model.layers.0.input_layernorm.weight False\n",
      "model.layers.0.post_attention_layernorm.weight False\n",
      "model.layers.1.self_attn.q_proj.base_layer.weight False\n",
      "model.layers.1.self_attn.q_proj.lora_A.weight True\n",
      "model.layers.1.self_attn.q_proj.lora_B.weight True\n",
      "model.layers.1.self_attn.k_proj.base_layer.weight False\n",
      "model.layers.1.self_attn.k_proj.lora_A.weight True\n",
      "model.layers.1.self_attn.k_proj.lora_B.weight True\n",
      "model.layers.1.self_attn.v_proj.base_layer.weight False\n",
      "model.layers.1.self_attn.v_proj.lora_A.weight True\n",
      "model.layers.1.self_attn.v_proj.lora_B.weight True\n",
      "model.layers.1.self_attn.o_proj.weight False\n",
      "model.layers.1.mlp.gate_proj.base_layer.weight False\n",
      "model.layers.1.mlp.gate_proj.lora_A.weight True\n",
      "model.layers.1.mlp.gate_proj.lora_B.weight True\n",
      "model.layers.1.mlp.up_proj.base_layer.weight False\n",
      "model.layers.1.mlp.up_proj.lora_A.weight True\n",
      "model.layers.1.mlp.up_proj.lora_B.weight True\n",
      "model.layers.1.mlp.down_proj.base_layer.weight False\n",
      "model.layers.1.mlp.down_proj.lora_A.weight True\n",
      "model.layers.1.mlp.down_proj.lora_B.weight True\n",
      "model.layers.1.input_layernorm.weight False\n",
      "model.layers.1.post_attention_layernorm.weight False\n",
      "model.norm.weight False\n",
      "lm_head.weight False\n"
     ]
    }
   ],
   "source": [
    "for n,p in model.named_parameters():\n",
    "    if any([lora_name in n for lora_name in ['lora_A', 'lora_B']]):\n",
    "        p.requires_grad = True\n",
    "    else:\n",
    "        p.requires_grad = False\n",
    "    \n",
    "    print(n, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff22c1-3a27-4d52-833f-5a4ab45ebcb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aec1f70-f0ec-4498-b49f-ae2908e26fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fd0e64-2731-4db1-befb-bebc6d74fbe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892f5400-f7a2-46b0-9ada-7022ee2d18b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ccb1ca-4ca6-431e-ac76-3e2f08d607a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237a3876-40ec-491b-ad6a-f6c3c03b3445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe8ba7b-6c7e-4f0b-9670-46255f37120b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5760650-43ac-4bca-872d-1c7939b8eae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6406042-3bec-4ffb-b956-0f300e763de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09c83bfd-bc5f-4e6c-8ad9-c621891edcfa",
   "metadata": {},
   "source": [
    "### Test Linear4bit Memory Eff Loading\n",
    "\n",
    "This will test that each rank has the correct quant state and params, also compare with original weights loaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "057decc8-852c-4c5c-b3b5-40cd8c634b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rank0 = torch.load(\"../data/summoned_lora_layer0_q_proj_base_layer_params_rank0.pt\")\n",
    "params_rank1 = torch.load(\"../data/summoned_lora_layer0_q_proj_base_layer_params_rank1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98fa6cc2-fcee-4740-b39a-8ea00796e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_state_rank0 = torch.load(\"../data/summoned_lora_layer0_q_proj_quant_state_rank0.pt\", map_location=\"cpu\")\n",
    "quant_state_rank1 = torch.load(\"../data/summoned_lora_layer0_q_proj_quant_state_rank1.pt\",  map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d0e1075-dc77-4d6c-8f82-6b27af267894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check gathered quantized weights are same in each rank\n",
    "for p1, p2 in zip(params_rank0, params_rank1):\n",
    "    p1 = p1[~p1.data.isnan()]\n",
    "    p2 = p2[~p2.data.isnan()]\n",
    "    assert torch.allclose(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9111f42-5f8e-4409-8aca-9b8f40f0307e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quant_type': 'nf4',\n",
       " 'absmax': tensor([230, 149,  74,  ..., 194, 175, 203], dtype=torch.uint8),\n",
       " 'blocksize': 64,\n",
       " 'quant_map': tensor([-1.0000, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,  0.0000,\n",
       "          0.0796,  0.1609,  0.2461,  0.3379,  0.4407,  0.5626,  0.7230,  1.0000]),\n",
       " 'dtype': 'bfloat16',\n",
       " 'shape': (8192, 8192),\n",
       " 'nested_absmax': tensor([0.0736, 0.0258, 0.0224,  ..., 0.0658, 0.0902, 0.0638]),\n",
       " 'nested_blocksize': 256,\n",
       " 'nested_quant_map': tensor([-9.9297e-01, -9.7891e-01, -9.6484e-01, -9.5078e-01, -9.3672e-01,\n",
       "         -9.2266e-01, -9.0859e-01, -8.9453e-01, -8.8047e-01, -8.6641e-01,\n",
       "         -8.5234e-01, -8.3828e-01, -8.2422e-01, -8.1016e-01, -7.9609e-01,\n",
       "         -7.8203e-01, -7.6797e-01, -7.5391e-01, -7.3984e-01, -7.2578e-01,\n",
       "         -7.1172e-01, -6.9766e-01, -6.8359e-01, -6.6953e-01, -6.5547e-01,\n",
       "         -6.4141e-01, -6.2734e-01, -6.1328e-01, -5.9922e-01, -5.8516e-01,\n",
       "         -5.7109e-01, -5.5703e-01, -5.4297e-01, -5.2891e-01, -5.1484e-01,\n",
       "         -5.0078e-01, -4.8672e-01, -4.7266e-01, -4.5859e-01, -4.4453e-01,\n",
       "         -4.3047e-01, -4.1641e-01, -4.0234e-01, -3.8828e-01, -3.7422e-01,\n",
       "         -3.6016e-01, -3.4609e-01, -3.3203e-01, -3.1797e-01, -3.0391e-01,\n",
       "         -2.8984e-01, -2.7578e-01, -2.6172e-01, -2.4766e-01, -2.3359e-01,\n",
       "         -2.1953e-01, -2.0547e-01, -1.9141e-01, -1.7734e-01, -1.6328e-01,\n",
       "         -1.4922e-01, -1.3516e-01, -1.2109e-01, -1.0703e-01, -9.8594e-02,\n",
       "         -9.5781e-02, -9.2969e-02, -9.0156e-02, -8.7344e-02, -8.4531e-02,\n",
       "         -8.1719e-02, -7.8906e-02, -7.6094e-02, -7.3281e-02, -7.0469e-02,\n",
       "         -6.7656e-02, -6.4844e-02, -6.2031e-02, -5.9219e-02, -5.6406e-02,\n",
       "         -5.3594e-02, -5.0781e-02, -4.7969e-02, -4.5156e-02, -4.2344e-02,\n",
       "         -3.9531e-02, -3.6719e-02, -3.3906e-02, -3.1094e-02, -2.8281e-02,\n",
       "         -2.5469e-02, -2.2656e-02, -1.9844e-02, -1.7031e-02, -1.4219e-02,\n",
       "         -1.1406e-02, -9.7187e-03, -9.1562e-03, -8.5938e-03, -8.0312e-03,\n",
       "         -7.4687e-03, -6.9063e-03, -6.3437e-03, -5.7813e-03, -5.2188e-03,\n",
       "         -4.6562e-03, -4.0937e-03, -3.5312e-03, -2.9687e-03, -2.4062e-03,\n",
       "         -1.8438e-03, -1.2812e-03, -9.4375e-04, -8.3125e-04, -7.1875e-04,\n",
       "         -6.0625e-04, -4.9375e-04, -3.8125e-04, -2.6875e-04, -1.5625e-04,\n",
       "         -8.8750e-05, -6.6250e-05, -4.3750e-05, -2.1250e-05, -7.7500e-06,\n",
       "         -3.2500e-06, -5.5000e-07,  0.0000e+00,  5.5000e-07,  3.2500e-06,\n",
       "          7.7500e-06,  2.1250e-05,  4.3750e-05,  6.6250e-05,  8.8750e-05,\n",
       "          1.5625e-04,  2.6875e-04,  3.8125e-04,  4.9375e-04,  6.0625e-04,\n",
       "          7.1875e-04,  8.3125e-04,  9.4375e-04,  1.2812e-03,  1.8438e-03,\n",
       "          2.4062e-03,  2.9687e-03,  3.5312e-03,  4.0937e-03,  4.6562e-03,\n",
       "          5.2188e-03,  5.7813e-03,  6.3437e-03,  6.9063e-03,  7.4687e-03,\n",
       "          8.0312e-03,  8.5938e-03,  9.1562e-03,  9.7187e-03,  1.1406e-02,\n",
       "          1.4219e-02,  1.7031e-02,  1.9844e-02,  2.2656e-02,  2.5469e-02,\n",
       "          2.8281e-02,  3.1094e-02,  3.3906e-02,  3.6719e-02,  3.9531e-02,\n",
       "          4.2344e-02,  4.5156e-02,  4.7969e-02,  5.0781e-02,  5.3594e-02,\n",
       "          5.6406e-02,  5.9219e-02,  6.2031e-02,  6.4844e-02,  6.7656e-02,\n",
       "          7.0469e-02,  7.3281e-02,  7.6094e-02,  7.8906e-02,  8.1719e-02,\n",
       "          8.4531e-02,  8.7344e-02,  9.0156e-02,  9.2969e-02,  9.5781e-02,\n",
       "          9.8594e-02,  1.0703e-01,  1.2109e-01,  1.3516e-01,  1.4922e-01,\n",
       "          1.6328e-01,  1.7734e-01,  1.9141e-01,  2.0547e-01,  2.1953e-01,\n",
       "          2.3359e-01,  2.4766e-01,  2.6172e-01,  2.7578e-01,  2.8984e-01,\n",
       "          3.0391e-01,  3.1797e-01,  3.3203e-01,  3.4609e-01,  3.6016e-01,\n",
       "          3.7422e-01,  3.8828e-01,  4.0234e-01,  4.1641e-01,  4.3047e-01,\n",
       "          4.4453e-01,  4.5859e-01,  4.7266e-01,  4.8672e-01,  5.0078e-01,\n",
       "          5.1484e-01,  5.2891e-01,  5.4297e-01,  5.5703e-01,  5.7109e-01,\n",
       "          5.8516e-01,  5.9922e-01,  6.1328e-01,  6.2734e-01,  6.4141e-01,\n",
       "          6.5547e-01,  6.6953e-01,  6.8359e-01,  6.9766e-01,  7.1172e-01,\n",
       "          7.2578e-01,  7.3984e-01,  7.5391e-01,  7.6797e-01,  7.8203e-01,\n",
       "          7.9609e-01,  8.1016e-01,  8.2422e-01,  8.3828e-01,  8.5234e-01,\n",
       "          8.6641e-01,  8.8047e-01,  8.9453e-01,  9.0859e-01,  9.2266e-01,\n",
       "          9.3672e-01,  9.5078e-01,  9.6484e-01,  9.7891e-01,  9.9297e-01,\n",
       "          1.0000e+00]),\n",
       " 'nested_dtype': 'float32',\n",
       " 'nested_offset': 0.03480497747659683}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_state_rank0.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fde78a2b-035d-4a42-9404-f425f561b876",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quant_type': 'nf4',\n",
       " 'absmax': tensor([230, 149,  74,  ..., 194, 175, 203], dtype=torch.uint8),\n",
       " 'blocksize': 64,\n",
       " 'quant_map': tensor([-1.0000, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,  0.0000,\n",
       "          0.0796,  0.1609,  0.2461,  0.3379,  0.4407,  0.5626,  0.7230,  1.0000]),\n",
       " 'dtype': 'bfloat16',\n",
       " 'shape': (8192, 8192),\n",
       " 'nested_absmax': tensor([0.0736, 0.0258, 0.0224,  ..., 0.0658, 0.0902, 0.0638]),\n",
       " 'nested_blocksize': 256,\n",
       " 'nested_quant_map': tensor([-9.9297e-01, -9.7891e-01, -9.6484e-01, -9.5078e-01, -9.3672e-01,\n",
       "         -9.2266e-01, -9.0859e-01, -8.9453e-01, -8.8047e-01, -8.6641e-01,\n",
       "         -8.5234e-01, -8.3828e-01, -8.2422e-01, -8.1016e-01, -7.9609e-01,\n",
       "         -7.8203e-01, -7.6797e-01, -7.5391e-01, -7.3984e-01, -7.2578e-01,\n",
       "         -7.1172e-01, -6.9766e-01, -6.8359e-01, -6.6953e-01, -6.5547e-01,\n",
       "         -6.4141e-01, -6.2734e-01, -6.1328e-01, -5.9922e-01, -5.8516e-01,\n",
       "         -5.7109e-01, -5.5703e-01, -5.4297e-01, -5.2891e-01, -5.1484e-01,\n",
       "         -5.0078e-01, -4.8672e-01, -4.7266e-01, -4.5859e-01, -4.4453e-01,\n",
       "         -4.3047e-01, -4.1641e-01, -4.0234e-01, -3.8828e-01, -3.7422e-01,\n",
       "         -3.6016e-01, -3.4609e-01, -3.3203e-01, -3.1797e-01, -3.0391e-01,\n",
       "         -2.8984e-01, -2.7578e-01, -2.6172e-01, -2.4766e-01, -2.3359e-01,\n",
       "         -2.1953e-01, -2.0547e-01, -1.9141e-01, -1.7734e-01, -1.6328e-01,\n",
       "         -1.4922e-01, -1.3516e-01, -1.2109e-01, -1.0703e-01, -9.8594e-02,\n",
       "         -9.5781e-02, -9.2969e-02, -9.0156e-02, -8.7344e-02, -8.4531e-02,\n",
       "         -8.1719e-02, -7.8906e-02, -7.6094e-02, -7.3281e-02, -7.0469e-02,\n",
       "         -6.7656e-02, -6.4844e-02, -6.2031e-02, -5.9219e-02, -5.6406e-02,\n",
       "         -5.3594e-02, -5.0781e-02, -4.7969e-02, -4.5156e-02, -4.2344e-02,\n",
       "         -3.9531e-02, -3.6719e-02, -3.3906e-02, -3.1094e-02, -2.8281e-02,\n",
       "         -2.5469e-02, -2.2656e-02, -1.9844e-02, -1.7031e-02, -1.4219e-02,\n",
       "         -1.1406e-02, -9.7187e-03, -9.1562e-03, -8.5938e-03, -8.0312e-03,\n",
       "         -7.4687e-03, -6.9063e-03, -6.3437e-03, -5.7813e-03, -5.2188e-03,\n",
       "         -4.6562e-03, -4.0937e-03, -3.5312e-03, -2.9687e-03, -2.4062e-03,\n",
       "         -1.8438e-03, -1.2812e-03, -9.4375e-04, -8.3125e-04, -7.1875e-04,\n",
       "         -6.0625e-04, -4.9375e-04, -3.8125e-04, -2.6875e-04, -1.5625e-04,\n",
       "         -8.8750e-05, -6.6250e-05, -4.3750e-05, -2.1250e-05, -7.7500e-06,\n",
       "         -3.2500e-06, -5.5000e-07,  0.0000e+00,  5.5000e-07,  3.2500e-06,\n",
       "          7.7500e-06,  2.1250e-05,  4.3750e-05,  6.6250e-05,  8.8750e-05,\n",
       "          1.5625e-04,  2.6875e-04,  3.8125e-04,  4.9375e-04,  6.0625e-04,\n",
       "          7.1875e-04,  8.3125e-04,  9.4375e-04,  1.2812e-03,  1.8438e-03,\n",
       "          2.4062e-03,  2.9687e-03,  3.5312e-03,  4.0937e-03,  4.6562e-03,\n",
       "          5.2188e-03,  5.7813e-03,  6.3437e-03,  6.9063e-03,  7.4687e-03,\n",
       "          8.0312e-03,  8.5938e-03,  9.1562e-03,  9.7187e-03,  1.1406e-02,\n",
       "          1.4219e-02,  1.7031e-02,  1.9844e-02,  2.2656e-02,  2.5469e-02,\n",
       "          2.8281e-02,  3.1094e-02,  3.3906e-02,  3.6719e-02,  3.9531e-02,\n",
       "          4.2344e-02,  4.5156e-02,  4.7969e-02,  5.0781e-02,  5.3594e-02,\n",
       "          5.6406e-02,  5.9219e-02,  6.2031e-02,  6.4844e-02,  6.7656e-02,\n",
       "          7.0469e-02,  7.3281e-02,  7.6094e-02,  7.8906e-02,  8.1719e-02,\n",
       "          8.4531e-02,  8.7344e-02,  9.0156e-02,  9.2969e-02,  9.5781e-02,\n",
       "          9.8594e-02,  1.0703e-01,  1.2109e-01,  1.3516e-01,  1.4922e-01,\n",
       "          1.6328e-01,  1.7734e-01,  1.9141e-01,  2.0547e-01,  2.1953e-01,\n",
       "          2.3359e-01,  2.4766e-01,  2.6172e-01,  2.7578e-01,  2.8984e-01,\n",
       "          3.0391e-01,  3.1797e-01,  3.3203e-01,  3.4609e-01,  3.6016e-01,\n",
       "          3.7422e-01,  3.8828e-01,  4.0234e-01,  4.1641e-01,  4.3047e-01,\n",
       "          4.4453e-01,  4.5859e-01,  4.7266e-01,  4.8672e-01,  5.0078e-01,\n",
       "          5.1484e-01,  5.2891e-01,  5.4297e-01,  5.5703e-01,  5.7109e-01,\n",
       "          5.8516e-01,  5.9922e-01,  6.1328e-01,  6.2734e-01,  6.4141e-01,\n",
       "          6.5547e-01,  6.6953e-01,  6.8359e-01,  6.9766e-01,  7.1172e-01,\n",
       "          7.2578e-01,  7.3984e-01,  7.5391e-01,  7.6797e-01,  7.8203e-01,\n",
       "          7.9609e-01,  8.1016e-01,  8.2422e-01,  8.3828e-01,  8.5234e-01,\n",
       "          8.6641e-01,  8.8047e-01,  8.9453e-01,  9.0859e-01,  9.2266e-01,\n",
       "          9.3672e-01,  9.5078e-01,  9.6484e-01,  9.7891e-01,  9.9297e-01,\n",
       "          1.0000e+00]),\n",
       " 'nested_dtype': 'float32',\n",
       " 'nested_offset': 0.03480497747659683}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_state_rank1.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d639c9f-0c99-4bed-9773-770a04fd260b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quant_type\n",
      "absmax\n",
      "blocksize\n",
      "quant_map\n",
      "dtype\n",
      "shape\n",
      "nested_absmax\n",
      "nested_blocksize\n",
      "nested_quant_map\n",
      "nested_dtype\n",
      "nested_offset\n"
     ]
    }
   ],
   "source": [
    "# check quant states are same in each rank\n",
    "for k,v in quant_state_rank0.as_dict().items():\n",
    "    print(k)\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        assert torch.equal(v, quant_state_rank1.as_dict()[k])\n",
    "    else:\n",
    "        assert v == quant_state_rank1.as_dict()[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e143405b-1e7d-4e96-95aa-8d53dbcac362",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quant_type': 'nf4',\n",
       " 'absmax': tensor([230, 149,  74,  ..., 194, 175, 203], dtype=torch.uint8),\n",
       " 'blocksize': 64,\n",
       " 'quant_map': tensor([-1.0000, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,  0.0000,\n",
       "          0.0796,  0.1609,  0.2461,  0.3379,  0.4407,  0.5626,  0.7230,  1.0000]),\n",
       " 'dtype': 'bfloat16',\n",
       " 'shape': (8192, 8192),\n",
       " 'nested_absmax': tensor([0.0736, 0.0258, 0.0224,  ..., 0.0658, 0.0902, 0.0638]),\n",
       " 'nested_blocksize': 256,\n",
       " 'nested_quant_map': tensor([-9.9297e-01, -9.7891e-01, -9.6484e-01, -9.5078e-01, -9.3672e-01,\n",
       "         -9.2266e-01, -9.0859e-01, -8.9453e-01, -8.8047e-01, -8.6641e-01,\n",
       "         -8.5234e-01, -8.3828e-01, -8.2422e-01, -8.1016e-01, -7.9609e-01,\n",
       "         -7.8203e-01, -7.6797e-01, -7.5391e-01, -7.3984e-01, -7.2578e-01,\n",
       "         -7.1172e-01, -6.9766e-01, -6.8359e-01, -6.6953e-01, -6.5547e-01,\n",
       "         -6.4141e-01, -6.2734e-01, -6.1328e-01, -5.9922e-01, -5.8516e-01,\n",
       "         -5.7109e-01, -5.5703e-01, -5.4297e-01, -5.2891e-01, -5.1484e-01,\n",
       "         -5.0078e-01, -4.8672e-01, -4.7266e-01, -4.5859e-01, -4.4453e-01,\n",
       "         -4.3047e-01, -4.1641e-01, -4.0234e-01, -3.8828e-01, -3.7422e-01,\n",
       "         -3.6016e-01, -3.4609e-01, -3.3203e-01, -3.1797e-01, -3.0391e-01,\n",
       "         -2.8984e-01, -2.7578e-01, -2.6172e-01, -2.4766e-01, -2.3359e-01,\n",
       "         -2.1953e-01, -2.0547e-01, -1.9141e-01, -1.7734e-01, -1.6328e-01,\n",
       "         -1.4922e-01, -1.3516e-01, -1.2109e-01, -1.0703e-01, -9.8594e-02,\n",
       "         -9.5781e-02, -9.2969e-02, -9.0156e-02, -8.7344e-02, -8.4531e-02,\n",
       "         -8.1719e-02, -7.8906e-02, -7.6094e-02, -7.3281e-02, -7.0469e-02,\n",
       "         -6.7656e-02, -6.4844e-02, -6.2031e-02, -5.9219e-02, -5.6406e-02,\n",
       "         -5.3594e-02, -5.0781e-02, -4.7969e-02, -4.5156e-02, -4.2344e-02,\n",
       "         -3.9531e-02, -3.6719e-02, -3.3906e-02, -3.1094e-02, -2.8281e-02,\n",
       "         -2.5469e-02, -2.2656e-02, -1.9844e-02, -1.7031e-02, -1.4219e-02,\n",
       "         -1.1406e-02, -9.7187e-03, -9.1562e-03, -8.5938e-03, -8.0312e-03,\n",
       "         -7.4687e-03, -6.9063e-03, -6.3437e-03, -5.7813e-03, -5.2188e-03,\n",
       "         -4.6562e-03, -4.0937e-03, -3.5312e-03, -2.9687e-03, -2.4062e-03,\n",
       "         -1.8438e-03, -1.2812e-03, -9.4375e-04, -8.3125e-04, -7.1875e-04,\n",
       "         -6.0625e-04, -4.9375e-04, -3.8125e-04, -2.6875e-04, -1.5625e-04,\n",
       "         -8.8750e-05, -6.6250e-05, -4.3750e-05, -2.1250e-05, -7.7500e-06,\n",
       "         -3.2500e-06, -5.5000e-07,  0.0000e+00,  5.5000e-07,  3.2500e-06,\n",
       "          7.7500e-06,  2.1250e-05,  4.3750e-05,  6.6250e-05,  8.8750e-05,\n",
       "          1.5625e-04,  2.6875e-04,  3.8125e-04,  4.9375e-04,  6.0625e-04,\n",
       "          7.1875e-04,  8.3125e-04,  9.4375e-04,  1.2812e-03,  1.8438e-03,\n",
       "          2.4062e-03,  2.9687e-03,  3.5312e-03,  4.0937e-03,  4.6562e-03,\n",
       "          5.2188e-03,  5.7813e-03,  6.3437e-03,  6.9063e-03,  7.4687e-03,\n",
       "          8.0312e-03,  8.5938e-03,  9.1562e-03,  9.7187e-03,  1.1406e-02,\n",
       "          1.4219e-02,  1.7031e-02,  1.9844e-02,  2.2656e-02,  2.5469e-02,\n",
       "          2.8281e-02,  3.1094e-02,  3.3906e-02,  3.6719e-02,  3.9531e-02,\n",
       "          4.2344e-02,  4.5156e-02,  4.7969e-02,  5.0781e-02,  5.3594e-02,\n",
       "          5.6406e-02,  5.9219e-02,  6.2031e-02,  6.4844e-02,  6.7656e-02,\n",
       "          7.0469e-02,  7.3281e-02,  7.6094e-02,  7.8906e-02,  8.1719e-02,\n",
       "          8.4531e-02,  8.7344e-02,  9.0156e-02,  9.2969e-02,  9.5781e-02,\n",
       "          9.8594e-02,  1.0703e-01,  1.2109e-01,  1.3516e-01,  1.4922e-01,\n",
       "          1.6328e-01,  1.7734e-01,  1.9141e-01,  2.0547e-01,  2.1953e-01,\n",
       "          2.3359e-01,  2.4766e-01,  2.6172e-01,  2.7578e-01,  2.8984e-01,\n",
       "          3.0391e-01,  3.1797e-01,  3.3203e-01,  3.4609e-01,  3.6016e-01,\n",
       "          3.7422e-01,  3.8828e-01,  4.0234e-01,  4.1641e-01,  4.3047e-01,\n",
       "          4.4453e-01,  4.5859e-01,  4.7266e-01,  4.8672e-01,  5.0078e-01,\n",
       "          5.1484e-01,  5.2891e-01,  5.4297e-01,  5.5703e-01,  5.7109e-01,\n",
       "          5.8516e-01,  5.9922e-01,  6.1328e-01,  6.2734e-01,  6.4141e-01,\n",
       "          6.5547e-01,  6.6953e-01,  6.8359e-01,  6.9766e-01,  7.1172e-01,\n",
       "          7.2578e-01,  7.3984e-01,  7.5391e-01,  7.6797e-01,  7.8203e-01,\n",
       "          7.9609e-01,  8.1016e-01,  8.2422e-01,  8.3828e-01,  8.5234e-01,\n",
       "          8.6641e-01,  8.8047e-01,  8.9453e-01,  9.0859e-01,  9.2266e-01,\n",
       "          9.3672e-01,  9.5078e-01,  9.6484e-01,  9.7891e-01,  9.9297e-01,\n",
       "          1.0000e+00]),\n",
       " 'nested_dtype': 'float32',\n",
       " 'nested_offset': 0.03480497747659683}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_state_rank0.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a1a9138-49e6-4ad6-9947-64aabc80980b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 4.9895e+33],\n",
       "        [-7.9810e-25],\n",
       "        [ 2.9687e+14],\n",
       "        ...,\n",
       "        [ 7.2876e+07],\n",
       "        [-3.9808e-24],\n",
       "        [-5.1300e+36]], dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_rank0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "047fac20-47b5-416d-9948-0d3f1eb39233",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_param = Params4bit(data=params_rank0[0], \n",
    "                               requires_grad=False, \n",
    "                               quant_state=quant_state_rank0,\n",
    "                               quant_type=quant_state_rank0.quant_type,\n",
    "                               quant_storage=params_rank0[0].dtype, \n",
    "                               bnb_quantized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35a6e750-26c0-427c-b63e-21e70e2c3123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.9895e+33],\n",
       "        [-7.9810e-25],\n",
       "        [ 2.9687e+14],\n",
       "        ...,\n",
       "        [ 7.2876e+07],\n",
       "        [-3.9808e-24],\n",
       "        [-5.1300e+36]], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_rank0[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adbba6bd-b52d-45fc-a695-1b7fc508abaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_state_rank0.to(\"cuda\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7aca49d3-1248-4370-aa66-fce1a8a34a81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quant_type': 'nf4',\n",
       " 'absmax': tensor([230, 149,  74,  ..., 194, 175, 203], device='cuda:0',\n",
       "        dtype=torch.uint8),\n",
       " 'blocksize': 64,\n",
       " 'quant_map': tensor([-1.0000, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,  0.0000,\n",
       "          0.0796,  0.1609,  0.2461,  0.3379,  0.4407,  0.5626,  0.7230,  1.0000]),\n",
       " 'dtype': 'bfloat16',\n",
       " 'shape': (8192, 8192),\n",
       " 'nested_absmax': tensor([0.0736, 0.0258, 0.0224,  ..., 0.0658, 0.0902, 0.0638], device='cuda:0'),\n",
       " 'nested_blocksize': 256,\n",
       " 'nested_quant_map': tensor([-9.9297e-01, -9.7891e-01, -9.6484e-01, -9.5078e-01, -9.3672e-01,\n",
       "         -9.2266e-01, -9.0859e-01, -8.9453e-01, -8.8047e-01, -8.6641e-01,\n",
       "         -8.5234e-01, -8.3828e-01, -8.2422e-01, -8.1016e-01, -7.9609e-01,\n",
       "         -7.8203e-01, -7.6797e-01, -7.5391e-01, -7.3984e-01, -7.2578e-01,\n",
       "         -7.1172e-01, -6.9766e-01, -6.8359e-01, -6.6953e-01, -6.5547e-01,\n",
       "         -6.4141e-01, -6.2734e-01, -6.1328e-01, -5.9922e-01, -5.8516e-01,\n",
       "         -5.7109e-01, -5.5703e-01, -5.4297e-01, -5.2891e-01, -5.1484e-01,\n",
       "         -5.0078e-01, -4.8672e-01, -4.7266e-01, -4.5859e-01, -4.4453e-01,\n",
       "         -4.3047e-01, -4.1641e-01, -4.0234e-01, -3.8828e-01, -3.7422e-01,\n",
       "         -3.6016e-01, -3.4609e-01, -3.3203e-01, -3.1797e-01, -3.0391e-01,\n",
       "         -2.8984e-01, -2.7578e-01, -2.6172e-01, -2.4766e-01, -2.3359e-01,\n",
       "         -2.1953e-01, -2.0547e-01, -1.9141e-01, -1.7734e-01, -1.6328e-01,\n",
       "         -1.4922e-01, -1.3516e-01, -1.2109e-01, -1.0703e-01, -9.8594e-02,\n",
       "         -9.5781e-02, -9.2969e-02, -9.0156e-02, -8.7344e-02, -8.4531e-02,\n",
       "         -8.1719e-02, -7.8906e-02, -7.6094e-02, -7.3281e-02, -7.0469e-02,\n",
       "         -6.7656e-02, -6.4844e-02, -6.2031e-02, -5.9219e-02, -5.6406e-02,\n",
       "         -5.3594e-02, -5.0781e-02, -4.7969e-02, -4.5156e-02, -4.2344e-02,\n",
       "         -3.9531e-02, -3.6719e-02, -3.3906e-02, -3.1094e-02, -2.8281e-02,\n",
       "         -2.5469e-02, -2.2656e-02, -1.9844e-02, -1.7031e-02, -1.4219e-02,\n",
       "         -1.1406e-02, -9.7187e-03, -9.1562e-03, -8.5938e-03, -8.0312e-03,\n",
       "         -7.4687e-03, -6.9063e-03, -6.3437e-03, -5.7813e-03, -5.2188e-03,\n",
       "         -4.6562e-03, -4.0937e-03, -3.5312e-03, -2.9687e-03, -2.4062e-03,\n",
       "         -1.8438e-03, -1.2812e-03, -9.4375e-04, -8.3125e-04, -7.1875e-04,\n",
       "         -6.0625e-04, -4.9375e-04, -3.8125e-04, -2.6875e-04, -1.5625e-04,\n",
       "         -8.8750e-05, -6.6250e-05, -4.3750e-05, -2.1250e-05, -7.7500e-06,\n",
       "         -3.2500e-06, -5.5000e-07,  0.0000e+00,  5.5000e-07,  3.2500e-06,\n",
       "          7.7500e-06,  2.1250e-05,  4.3750e-05,  6.6250e-05,  8.8750e-05,\n",
       "          1.5625e-04,  2.6875e-04,  3.8125e-04,  4.9375e-04,  6.0625e-04,\n",
       "          7.1875e-04,  8.3125e-04,  9.4375e-04,  1.2812e-03,  1.8438e-03,\n",
       "          2.4062e-03,  2.9687e-03,  3.5312e-03,  4.0937e-03,  4.6562e-03,\n",
       "          5.2188e-03,  5.7813e-03,  6.3437e-03,  6.9063e-03,  7.4687e-03,\n",
       "          8.0312e-03,  8.5938e-03,  9.1562e-03,  9.7187e-03,  1.1406e-02,\n",
       "          1.4219e-02,  1.7031e-02,  1.9844e-02,  2.2656e-02,  2.5469e-02,\n",
       "          2.8281e-02,  3.1094e-02,  3.3906e-02,  3.6719e-02,  3.9531e-02,\n",
       "          4.2344e-02,  4.5156e-02,  4.7969e-02,  5.0781e-02,  5.3594e-02,\n",
       "          5.6406e-02,  5.9219e-02,  6.2031e-02,  6.4844e-02,  6.7656e-02,\n",
       "          7.0469e-02,  7.3281e-02,  7.6094e-02,  7.8906e-02,  8.1719e-02,\n",
       "          8.4531e-02,  8.7344e-02,  9.0156e-02,  9.2969e-02,  9.5781e-02,\n",
       "          9.8594e-02,  1.0703e-01,  1.2109e-01,  1.3516e-01,  1.4922e-01,\n",
       "          1.6328e-01,  1.7734e-01,  1.9141e-01,  2.0547e-01,  2.1953e-01,\n",
       "          2.3359e-01,  2.4766e-01,  2.6172e-01,  2.7578e-01,  2.8984e-01,\n",
       "          3.0391e-01,  3.1797e-01,  3.3203e-01,  3.4609e-01,  3.6016e-01,\n",
       "          3.7422e-01,  3.8828e-01,  4.0234e-01,  4.1641e-01,  4.3047e-01,\n",
       "          4.4453e-01,  4.5859e-01,  4.7266e-01,  4.8672e-01,  5.0078e-01,\n",
       "          5.1484e-01,  5.2891e-01,  5.4297e-01,  5.5703e-01,  5.7109e-01,\n",
       "          5.8516e-01,  5.9922e-01,  6.1328e-01,  6.2734e-01,  6.4141e-01,\n",
       "          6.5547e-01,  6.6953e-01,  6.8359e-01,  6.9766e-01,  7.1172e-01,\n",
       "          7.2578e-01,  7.3984e-01,  7.5391e-01,  7.6797e-01,  7.8203e-01,\n",
       "          7.9609e-01,  8.1016e-01,  8.2422e-01,  8.3828e-01,  8.5234e-01,\n",
       "          8.6641e-01,  8.8047e-01,  8.9453e-01,  9.0859e-01,  9.2266e-01,\n",
       "          9.3672e-01,  9.5078e-01,  9.6484e-01,  9.7891e-01,  9.9297e-01,\n",
       "          1.0000e+00], device='cuda:0'),\n",
       " 'nested_dtype': 'float32',\n",
       " 'nested_offset': 0.03480497747659683}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_state_rank0.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61efa86b-cbb5-4e23-80b8-34489bc47785",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = params_rank0[0].data.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c440294-52ba-4fca-959b-1d59138ba0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dequantized_weight = F.dequantize_4bit(data, quant_state_rank0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ee84a20-4094-476d-b991-7e270696e113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.0076,  0.0000,  ...,  0.0024,  0.0131,  0.0024],\n",
       "        [ 0.0093, -0.0066,  0.0166,  ...,  0.0105, -0.0057,  0.0105],\n",
       "        [ 0.0012,  0.0038,  0.0052,  ..., -0.0061, -0.0028, -0.0044],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0234, -0.0118,  ..., -0.0209,  0.0000,  0.0074],\n",
       "        [ 0.0124,  0.0029,  0.0206,  ..., -0.0032, -0.0347, -0.0098],\n",
       "        [ 0.0116, -0.0087,  0.0037,  ...,  0.0000,  0.0525,  0.0231]],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dequantized_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d189849e-cdf3-4321-be2c-6cd53a694385",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"codellama/CodeLlama-34b-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6151cc2-3f42-41be-b608-cc1d2738c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = hub.cached_file(model_name, SAFE_WEIGHTS_INDEX_NAME)\n",
    "files, _ = hub.get_checkpoint_shard_files(model_name, idx)\n",
    "orig_weight = None\n",
    "for filename in files:\n",
    "    weights = safetensors.torch.load_file(filename)\n",
    "    for name, param in weights.items():\n",
    "        # print(name)\n",
    "        if name == \"model.layers.0.self_attn.q_proj.weight\":\n",
    "            orig_weight = param\n",
    "            break\n",
    "        # load_param(model, name, param, dtype=torch_dtype, device=rank, \n",
    "        #            skip_names=load_param_skip_names, to_cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af94ca28-6ecc-4861-8a45-c98fb22c2f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some devation is expected from dequantization\n",
    "# Taken from : peft/tests/.../test_4bit_merge_and_disable_lora - Stricter tolerance values needed?\n",
    "assert torch.allclose(dequantized_weight.cpu(), orig_weight, atol=0.01, rtol=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfa13f04-5760-4628-b2b6-7d71139969f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "Parameter(Params4bit([[ 4.9895e+33],\n",
       "            [-7.9810e-25],\n",
       "            [ 2.9687e+14],\n",
       "            ...,\n",
       "            [ 7.2876e+07],\n",
       "            [-3.9808e-24],\n",
       "            [-5.1300e+36]], dtype=torch.bfloat16))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c62fd0-b203-4302-aea8-4d7239a205a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdafaa-75d5-4343-8cb7-a74d25e24392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3531c52-a685-42c9-91da-c998b4cd10c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
