{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78ebc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "import gspread\n",
    "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d1ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = gspread.oauth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5219bb",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c3dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {\"model_name\":\"meta-llama/Llama-2-7b-hf\", \"model_size\":7}, \n",
    "    {\"model_name\":\"meta-llama/Llama-2-13b-hf\", \"model_size\":13},\n",
    "    {\"model_name\":\"codellama/CodeLlama-34b-hf\", \"model_size\":34},\n",
    "    {\"model_name\":\"meta-llama/Llama-2-70b-hf\", \"model_size\":70}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f3d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for m in models:\n",
    "#     cfg = AutoConfig.from_pretrained(m['model_name'])\n",
    "#     m['config'] = cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen = [{\"seqlen\":256}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2f8d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_bs = [{\"max_bs\":None}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d25c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = [{\"bs\":None}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6defaf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_offloading = [{\"cpu_offloading\":False}, {\"cpu_offloading\":True}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564866c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "distrib_type = [{\"distrib_type\":\"FSDP\"}, {\"distrib_type\":\"DDP\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03572dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_type = [{\"ft_type\":\"LoRA\"}, {\"ft_type\":\"QLoRA\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdd62fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RTX 3090 is not available in cloud providers A5000 also has 24GB memory\n",
    "gpus = [{\"gpu_model\":\"A5000\", \"num_gpus\":2, \"gpu_mem\":24, \"total_gpu_mem\":48, \"nvlink\":\"False\"},\n",
    "        {\"gpu_model\":\"A100-40\", \"num_gpus\":8, \"gpu_mem\":40, \"total_gpu_mem\":320, \"nvlink\":\"True\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f1386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb = [{\"wandb_link\":None,\n",
    "          \"memory_peak\":None, \n",
    "          \"memory_after_model_creation\":None,\n",
    "          \"memory_after_model_wrap\":None,          \n",
    "          \"memory_before_forward\":None,\n",
    "          \"memory_after_forward\":None,\n",
    "          \"memory_before_backward\":None,\n",
    "          \"memory_after_backward\":None, \n",
    "          \"time_taken\":None}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd72646",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_ckpt = [{\"use_gradient_checkpointing\":True}, {\"use_gradient_checkpointing\":False}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d394429",
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = [models, seqlen, max_bs, bs, grad_ckpt, cpu_offloading, distrib_type, ft_type, gpus, wandb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fab4270",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = list(itertools.product(*iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f2f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cad6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list_of_dicts(l):\n",
    "    final_d = {}\n",
    "    for d in l: \n",
    "        for k,v in d.items():\n",
    "            if k in final_d:\n",
    "                raise ValueError(f\"Key {k} exists.\")\n",
    "            final_d[k] = v\n",
    "    return final_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a910744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_flat = [flatten_list_of_dicts(exp) for exp in experiments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606c605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(experiments_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b6c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude lora ddp\n",
    "mask = ~((df['ft_type'] == 'LoRA') & (df['distrib_type'] == 'DDP'))\n",
    "# no cpu-offloading with ddp\n",
    "mask = np.logical_and(mask, ~((df['cpu_offloading'] == True) & (df['distrib_type'] == 'DDP')))\n",
    "\n",
    "df = df[mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd687cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8770de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d625f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gspread\n",
    "# !pip install gspread-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a00615",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://docs.google.com/spreadsheets/d/1JSQbnkwtqPgc-_wqI3LTCJI6jWCaWafubK0ontWR2_Y\"\n",
    "sheet = gc.open_by_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad54f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will overwrite the existing sheet!\n",
    "# use other utils from gspread to add data to specific cells.\n",
    "worksheet = sheet.get_worksheet_by_id(0)\n",
    "set_with_dataframe(worksheet, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8213e2ab",
   "metadata": {},
   "source": [
    "### Modify Experiments\n",
    "\n",
    "Flag experiments based on the theoretical limits excluding the activations.\n",
    "\n",
    "**Note:** In DDP script cast all model params to bfloat16 except for RoPE layers.\n",
    "\n",
    "1) DDP requires all params, optimizer states, activations to fit into a single GPU.\n",
    "\n",
    "2) Compute approx memory requirement per GPU with FSDP full sharing, consider cases with and without CPU offloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fad2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://docs.google.com/spreadsheets/d/1JSQbnkwtqPgc-_wqI3LTCJI6jWCaWafubK0ontWR2_Y\"\n",
    "sheet = gc.open_by_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f9835",
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet = sheet.get_worksheet_by_id(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6dbda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = worksheet.get_all_values()\n",
    "df = pd.DataFrame(vals[1:], columns=vals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c10eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ffe007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35082b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420b5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation memory per layer: https://arxiv.org/pdf/2205.05198.pdf\n",
    "bs = 1 \n",
    "sl = 256\n",
    "h = 4096\n",
    "a = 32\n",
    "(bs * sl * h * (34 + 5 * (a * sl / h))) / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a8b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude optimizer states since lora updates a small fraction of weights\n",
    "# exclude activations \n",
    "oom_ignored = []\n",
    "for row in df.itertuples():\n",
    "    if row.cpu_offloading != 'TRUE':\n",
    "        approx_mem_req = int(row.model_size) * 2 / (int(row.num_gpus) if row.distrib_type == 'FSDP' else 1)\n",
    "        oom_ignored.append(approx_mem_req > int(row.total_gpu_mem))\n",
    "    else:\n",
    "        oom_ignored.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638b97e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['oom_ignored'] = oom_ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65cf179",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['oom_ignored'].mean(), df['oom_ignored'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc63ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_with_dataframe(worksheet, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d03fc85",
   "metadata": {},
   "source": [
    "### Create Training Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850ed294",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df.query(\"oom_ignored == 'FALSE' or not oom_ignored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e84219",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113fff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_gpu_commands = []\n",
    "large_gpu_commands = []\n",
    "\n",
    "for _, row in sub_df.iterrows():\n",
    "    cmd_args = [\"python train.py\",\n",
    "                \"--batch_size 128\", # divide by 2 every retry\n",
    "                \"--num_epochs 1\",\n",
    "                \"--dataset alpaca_sample\",\n",
    "                \"--use_flash_attention\",\n",
    "                \"--precision bf16_buffers_autocast\",\n",
    "                \"--log_to wandb\",\n",
    "    ]\n",
    "\n",
    "    if row.distrib_type == \"DDP\":\n",
    "        cmd_args.append(\"--use_dpp\")\n",
    "    elif row.distrib_type == \"FSDP\":\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown distrib_type {distrib_type}\")\n",
    "\n",
    "    cmd_args.append(f\"--model_name {row.model_name}\")\n",
    "\n",
    "    cmd_args.append(f\"--context_length {row.seqlen}\")\n",
    "    \n",
    "    if row.use_gradient_checkpointing == \"TRUE\":\n",
    "        cmd_args.append(\"--use_gradient_checkpointing True\")\n",
    "    else:\n",
    "        cmd_args.append(\"--use_gradient_checkpointing False\")\n",
    "    \n",
    "    if row.cpu_offloading == \"TRUE\":\n",
    "        cmd_args.append(\"--use_cpu_offload\")\n",
    "\n",
    "    if row.ft_type == \"LoRA\":\n",
    "        cmd_args.append(\"--train_type lora\")\n",
    "    elif row.ft_type == \"QLoRA\":\n",
    "        cmd_args.append(\"--train_type qlora\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown ft_type {ft_type}\")\n",
    "        \n",
    "    if row.gpu_model == \"A100-40\":\n",
    "        large_gpu_commands.append(\" \".join(cmd_args))\n",
    "    elif row.gpu_model == \"A5000\":\n",
    "        small_gpu_commands.append(\" \".join(cmd_args))\n",
    "    else:\n",
    "        ValueError(\"Unknown gpu model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45cc821",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../benchmarking\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb58d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../benchmarking/small_gpu_benchmarking.sh\", \"w\") as f: \n",
    "    f.write(\"\\n\".join(small_gpu_commands))\n",
    "\n",
    "with open(\"../benchmarking/large_gpu_benchmarking.sh\", \"w\") as f: \n",
    "    f.write(\"\\n\".join(large_gpu_commands))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366931c9",
   "metadata": {},
   "source": [
    "### Update Sheet with Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78001191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fbd127",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1cd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://docs.google.com/spreadsheets/d/1JSQbnkwtqPgc-_wqI3LTCJI6jWCaWafubK0ontWR2_Y\"\n",
    "sheet = gc.open_by_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4de6e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_worksheet = sheet.get_worksheet_by_id(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b874b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_worksheet = sheet.get_worksheet_by_id(74399953)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5effe246",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = empty_worksheet.get_all_values()\n",
    "df = pd.DataFrame(vals[1:], columns=vals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b34280",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0ce5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9362e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_project = \"answerdotai/fsdp-benchmarking\"\n",
    "\n",
    "wandb_cols = ['memory_peak', 'memory_after_model_creation',\n",
    "              'memory_after_model_wrap', 'memory_before_forward',\n",
    "              'memory_after_forward', 'memory_after_backward', \n",
    "              'time_taken']\n",
    "\n",
    "empty_logs = pd.Series({c:None for c in wandb_cols})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f74bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logs = []\n",
    "for row in df.itertuples():\n",
    "    if row.wandb_link == \"\": \n",
    "        wandb_logs.append(empty_logs)\n",
    "    else:\n",
    "        expid = row.wandb_link.split(\"runs/\")[-1].split(\"/\")[0].split(\"?\")[0]\n",
    "        print(row.wandb_link, expid)\n",
    "        run = api.run(wandb_project + \"/\" + expid)\n",
    "        history_df = run.history()\n",
    "        existing_cols = list(set(history_df.columns).intersection(wandb_cols))\n",
    "        wandb_logs.append(history_df[existing_cols].fillna(-1e30).max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf02932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logs_df = pd.concat(wandb_logs, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27635e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in wandb_logs_df.columns:\n",
    "    if c.startswith(\"memory\"):\n",
    "        wandb_logs_df[c] = wandb_logs_df[c] / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153973bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[wandb_logs_df.columns] = wandb_logs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82a0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa1561",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_with_dataframe(filled_worksheet, df, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fd5775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e268230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b7b240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env-modeling-py",
   "language": "python",
   "name": "conda-env-modeling-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
